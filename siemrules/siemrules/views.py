import uuid
from rest_framework import (
    viewsets,
    parsers,
    decorators,
    mixins,
    renderers,
    status,
    validators,
)
from siemrules.siemrules import correlations, models, reports
from siemrules.siemrules import serializers
from siemrules.siemrules.correlations.serializers import (
    CorrelationRuleSerializer,
    DRFCorrelationRule,
)
from drf_spectacular.types import OpenApiTypes
from siemrules.siemrules.modifier import (
    DRFDetection,
    DRFSigmaRule,
    yaml_to_detection,
)
from siemrules.siemrules.serializers import (
    CorrelationJobSerializer,
    FileDocumentSerializer,
    FileSerializer,
    ImageSerializer,
    JobSerializer,
    ProfileSerializer,
)
from rest_framework.exceptions import ParseError
from dogesec_commons.objects.helpers import OBJECT_TYPES

from rest_framework import request, exceptions
from django.http import HttpRequest, HttpResponse
from drf_spectacular.utils import (
    extend_schema,
    extend_schema_view,
    OpenApiParameter,
    OpenApiExample,
    OpenApiResponse,
)
import textwrap
import typing
from dogesec_commons.utils import Pagination, Ordering
from siemrules.siemrules.md_helper import MarkdownImageReplacer, mistune
from siemrules.siemrules.utils import PDFRenderer, SigmaRuleParser, SigmaRuleRenderer
from siemrules.worker import tasks
from rest_framework.response import Response
from django_filters.rest_framework import (
    FilterSet,
    DjangoFilterBackend,
    ChoiceFilter,
    CharFilter,
    BaseInFilter,
    Filter,
)

from siemrules.siemrules.autoschema import DEFAULT_400_ERROR, DEFAULT_404_ERROR
from django.http import FileResponse, HttpResponseNotFound
from siemrules.siemrules import arangodb_helpers

from drf_spectacular.views import SpectacularAPIView
from rest_framework.response import Response


class SchemaViewCached(SpectacularAPIView):
    _schema = None

    def _get_schema_response(self, request):
        version = (
            self.api_version or request.version or self._get_version_parameter(request)
        )
        if not self.__class__._schema:
            generator = self.generator_class(
                urlconf=self.urlconf, api_version=version, patterns=self.patterns
            )
            self.__class__._schema = generator.get_schema(
                request=request, public=self.serve_public
            )
        return Response(
            data=self.__class__._schema,
            headers={
                "Content-Disposition": f'inline; filename="{self._get_filename(request, version)}"'
            },
        )


@extend_schema_view(
    create_from_intel=extend_schema(
        summary="Upload an intelligence report to convert into Sigma Base Rules",
        description=textwrap.dedent(
            """
            Upload an intelligence report to be processed by SIEM Rules.

            During processing a file is turned into markdown by [file2txt](https://github.com/muchdogesec/file2txt/), which is then passed to [txt2detection](https://github.com/muchdogesec/txt2detection/) to turn into rules.

            One or more Base Rules will be created from the report depending on its content.

            Please note the default behaviour on rule creation for properties that CANNOT be passed;

            * `id`: generated by SIEM Rules. It is possible that one or more rules might be created from the input report.
            * `title`: will be assigned by the AI
            * `description`: will be assigned by the AI
            * `status`: always `experimental`
            * `level`:  will be assigned by the AI

            The response will contain the Job information, including the Job `id`. This can be used with the GET Jobs by STIX ID endpoint to monitor the status of the Job.
            """
        ),
    ),
    create_from_sigma=extend_schema(
        summary="Upload an existing Sigma Base Rule",
        description=textwrap.dedent(
            """
            If you have an existing Sigma Rule, you can upload it via this endpoint to create it as a Rule in SIEM Rules.

            You need to enter the entire YML of the rule. [The YML entered will be validated against the Sigma specification](https://github.com/SigmaHQ/sigma-specification/blob/main/specification/sigma-rules-specification.md). You will receive an error if validation fails. 

            For reference your updated rule MUST contain the following properties;

            * `title` (string): `title` of the rule. Will overwrite any existing value.
            * `logsource` (valid Sigma logsource): [a valid Sigma `logsource` entry](https://github.com/SigmaHQ/sigma-specification/blob/main/specification/sigma-rules-specification.md)
            * `detection` (valid Sigma detection): [a valid Sigma `detection` entry](https://github.com/SigmaHQ/sigma-specification/blob/main/specification/sigma-rules-specification.md)
            * `tags` (`tlp`): the rule must contain only one `tlp.` tag value, either `tlp.clear`, `tlp.green`, tlp.amber`, `tlp.amber+strict`, `tlp.red`.

            You CAN optionally pass the following Sigma Base rule properties in the rule but please note the behaviour of doing so;

            * `id`: if the rule uploaded contains an existing `id` value, it will be changed by SIEM Rules to ensure collisions between IDs don't occur. The original `id` will be referenced inside the new rule under the `related` property
            * `author`: all rules in SIEM Rules are tied to a STIX Identity object. If the rule contains;
                * a string, that does not start with `identity--`, SIEM Rules will attempt to identify if an Identity already exists for this object (identity ID is generated using UUIDv5, namespace `8ef05850-cb0d-51f7-80be-50e4376dbe63` and the value used is the `author`). If it does, that ID will be used. If not, a new Identity object will be created using the same logic.
                * a string that starts with `identity--`, SIEM Rules will attempt to identify if an Identity already exists for this object. If it does, that identity will be used. If not, you will recieve an error
                * a JSON object with a valid STIX Identity ID, the Identity ID will be validated. If ID already exists, that will be used to create the rule. If ID does not exist, the Identity payload will be used to create an Identity object and that will be used.

            If no value passed for the following values, please note the default behaviour that can potentially modify the rule created:

            * `tags` (`tlp`): if the rule is missing a TLP tag, it will be assigned the tag `tlp.clear` by default.
            * `author`: if no `author` value, the SIEM Rules identity will be used (`identity--8ef05850-cb0d-51f7-80be-50e4376dbe63`)
            * `date`: the time of the upload will be used

            If any part of the validation fails the rule will not be created.

            The response will contain the Job information, including the Job `id`. This can be used with the GET Jobs by STIX ID endpoint to monitor the status of the Job.
            """
        ),
    ),
    create_from_prompt=extend_schema(
        summary="Enter a text prompt to convert into Sigma Base Rule",
        description=textwrap.dedent(
            """
            Use this endpoint to create Base Rules from a prompt.

            One or more Base Rules will be created from the prompt depending on its content.

            The following key / values are accepted in the body of the request:

            * `text_input` (required): this is a string of text that will be passed to the AI to create the rule. Generally this should take the form of a prompt; e.g. `write a detection rule that identified failed logins`, `write a detection rule that detects 1.1.1.1 or 2.2.2.2`, etc.
            * `name` (required): This will be assigned to the File and Report object created. Note, the names of each detection rule generated will be automatically. Max 256 characters. This is a txt2detection setting.
            * `created` (optional) by default all object created times will take the time the script was run. If you want to explicitly set these times you can do so using this flag. Pass the value in the format `YYYY-MM-DDThh:mm:ss` e.g. `2020-01-01T00:00:00`. This is a txt2detection setting.
            * `report_id` (optional): Pass a full STIX Report ID in the format `report--<UUID>` (e.g. `report--3fa85f64-5717-4562-b3fc-2c963f66afa6`. It will be use to generate the STIX Report ID generated to capture the file uploaded (the Indicator ID for the Rule will be different). If not passed, this value will be randomly generated for this file. Must be unique. This is a txt2detection setting.
            * `identity` (optional): This will be used as the `created_by_ref` for all created SDOs and SROs and as the `author` value in the Base Rule. This is a full STIX Identity JSON. e.g. `{"type":"identity","spec_version":"2.1","id":"identity--b1ae1a15-6f4b-431e-b990-1b9678f35e15","name":"Dummy Identity"}`. If no value is passed, the [SIEM Rules identity object](https://raw.githubusercontent.com/muchdogesec/stix4doge/refs/heads/main/objects/identity/siemrules.json) will be used. This is a txt2detection setting.
            * `labels` (optional): Will be added to the `labels` of the Report and Indicator SDOs created, and `tags` in the Rule itself. Must pass in format `namespace.value`. This is a txt2detection setting. **NOTE**: you cannot use the reserved `tlp`. Use the `tlp_level` setting to set this. **NOTE**: you cannot use reserved namespaces `cve.` and `attack.`. The AI will add these based on the rule content.
            * `tlp_level` (optional): This will be assigned to all SDOs and SROs created and added to the Base Rule as a tag (e.g. `tlp.red`). SIEM Rules uses TLPv2. This is a txt2detection setting. Either `clear`, `green`, `amber`, `amber+strict`, `red`. If not passed default is `clear`. 
             * `license` (optional): [License of the rule according the SPDX ID specification](https://spdx.org/licenses/) (e.g. `MIT`). Will be added to the Rule. This is a txt2detection setting.
             * `references`: A list of URLs to be added as `references` in the Sigma Rule property and in the `external_references` property of the Indicator and Report STIX object created. e.g `"https://www.google.com/"`, `"https://www.facebook.com/"`. We don't currently assign AI to generate `references` due to hallucinations.
            * `ai_provider` (required): An AI provider and model to be used for rule generation in format `provider:model` e.g. `openai:gpt-4o`. This is a txt2detection setting.
            * `ignore_embedded_relationships` (optional, default: `false`): boolean, if `true` passed, this will stop ANY embedded relationships from being generated. This applies for all object types (SDO, SCO, SRO, SMO). If you want to target certain object types see `ignore_embedded_relationships_sro` and `ignore_embedded_relationships_sro` flags. This is a stix2arango setting.
            * `ignore_embedded_relationships_sro` (optional, default: false): boolean, if true passed, will stop any embedded relationships from being generated from SRO objects (type = `relationship`). This is a stix2arango setting.
            * `ignore_embedded_relationships_smo` (optional, default: false): boolean, if true passed, will stop any embedded relationships from being generated from SMO objects (type = `marking-definition`, `extension-definition`, `language-content`). This is a stix2arango setting.

            You cannot set the following properties when creating a rule in this mode:

            * `id`: generated by SIEM Rules
            * `title`: will be assigned by the AI, can be modified later
            * `description`: will be assigned by the AI, can be modified later
            * `status`: always `experimental`, can be modified later
            * `level`:  will be assigned by the AI, can be modified later

            The response will contain the Job information, including the Job `id`. This can be used with the GET Jobs by STIX ID endpoint to monitor the status of the Job.
            """
        ),
    ),
    list=extend_schema(
        summary="Search and retrieve a list of uploaded Files",
        description=textwrap.dedent(
            """
            This endpoint allows you to search for Files you've uploaded. This endpoint is particularly useful if you want to download the original File uploaded or find the Report object created for the uploaded File so you can retrieve the objects created for it.
            """
        ),
        responses={200: FileSerializer, 400: DEFAULT_400_ERROR},
    ),
    destroy=extend_schema(
        summary="Delete a File by STIX ID",
        description=textwrap.dedent(
            """
            This endpoint will delete a File using its ID. It will also delete the markdown, images and original file stored for this File.

            IMPORTANT: this request WILL delete the Report SDO created from the file, any any other STIX objects created from this file during extractions.
            """
        ),
    ),
    retrieve=extend_schema(
        summary="Get a File by STIX ID",
        description=textwrap.dedent(
            """
            This endpoint will return information for a specific File using its ID.
            """
        ),
    ),
    images=extend_schema(
        responses={
            200: ImageSerializer(many=True),
            404: DEFAULT_404_ERROR,
            400: DEFAULT_400_ERROR,
        },
        filters=False,
        summary="Retrieve images found in a File",
        description=textwrap.dedent(
            """
            When [file2txt](https://github.com/muchdogesec/file2txt/) processes a file it will extract all images from the file and store them locally. You can see these images referenced in the markdown produced (see File markdown endpoint). This endpoint lists the image files found in the File selected.
            """
        ),
    ),
    markdown=extend_schema(
        responses={200: {}, 404: DEFAULT_404_ERROR},
        summary="Get the processed markdown for a File",
        description=textwrap.dedent(
            """
            When a file is uploaded it is converted to markdown using [file2txt](https://github.com/muchdogesec/file2txt/) which is subsequently used to make extractions from. This endpoint will return that output.
            
            This endpoint is useful for debugging issues in extractions when you think there could be an issue with the content being passed to the extractors.
            """
        ),
    ),
)
class FileView(
    mixins.ListModelMixin,
    mixins.DestroyModelMixin,
    mixins.RetrieveModelMixin,
    viewsets.GenericViewSet,
):
    openapi_tags = ["Files"]
    pagination_class = Pagination("files")
    serializer_class = serializers.FileSerializer
    parser_classes = [parsers.MultiPartParser]

    filter_backends = [DjangoFilterBackend, Ordering]
    ordering_fields = ["created", "name"]
    ordering = "created_descending"

    lookup_url_kwarg = "file_id"

    def get_queryset(self):
        return models.File.objects.all()

    class filterset_class(FilterSet):
        report_id = BaseInFilter(
            method="filter_report_id",
            help_text="Filter the results by the STIX Report ID generated for this File. Pass the full STIX ID, e.g. `report--3fa85f64-5717-4562-b3fc-2c963f66afa6`.",
        )
        name = CharFilter(
            help_text="Filter by the name of the File (entered on input). Search is wildcard so `exploit` will match `exploited`, `exploits`, etc."
        )
        tlp_level = ChoiceFilter(
            help_text="Filter the files by the TLP level selected at input.",
            choices=models.TLP_Levels.choices,
        )
        created_by_ref = BaseInFilter(
            "identity__id",
            help_text="Filter the results by only the Files created by this identity. Pass the full STIX ID of the Identity object, e.g. `identity--b1ae1a15-6f4b-431e-b990-1b9678f35e15`.",
        )

        def filter_report_id(self, qs, field_name, value: str):
            file_id = [reports.report_id_as_id(v) for v in value]
            return qs.filter(pk__in=file_id)

    @extend_schema(
        responses={201: serializers.JobSerializer, 400: DEFAULT_400_ERROR},
        request=serializers.FileSerializer,
    )
    @decorators.action(methods=["POST"], detail=False, url_path="intel")
    def create_from_intel(self, request, *args, **kwargs):
        serializer = FileDocumentSerializer(data=request.data)
        serializer.is_valid(raise_exception=True)
        temp_file = request.FILES["file"]
        file_instance = serializer.save(mimetype=temp_file.content_type)
        job_instance = models.Job.objects.create(
            file=file_instance, type=models.JobType.FILE_FILE
        )
        job_serializer = JobSerializer(job_instance)
        tasks.new_task(job_instance)
        return Response(job_serializer.data, status=status.HTTP_201_CREATED)

    @extend_schema(
        responses={201: serializers.JobSerializer, 400: DEFAULT_400_ERROR},
        request=DRFSigmaRule.drf_serializer,
    )
    @decorators.action(
        methods=["POST"], detail=False, url_path="yml", parser_classes=[SigmaRuleParser]
    )
    def create_from_sigma(self, request: request.Request, *args, **kwargs):
        request_body = request.body
        serializer = DRFSigmaRule.drf_serializer(data=request.data)
        serializer.is_valid(raise_exception=True)
        rule = DRFSigmaRule.model_validate(serializer.validated_data)
        file_serializer = rule.to_file_serializer(request_body=request_body)
        file_instance = file_serializer.save(mimetype="application/x-yaml")
        job_instance = models.Job.objects.create(
            file=file_instance, type=models.JobType.FILE_SIGMA
        )
        job_serializer = JobSerializer(job_instance)
        tasks.new_task(job_instance)
        return Response(job_serializer.data, status=status.HTTP_201_CREATED)

    @extend_schema(
        responses={201: serializers.JobSerializer, 400: DEFAULT_400_ERROR},
        request=serializers.FilePromptSerializer,
    )
    @decorators.action(
        methods=["POST"],
        detail=False,
        parser_classes=[parsers.JSONParser],
        url_path="prompt",
    )
    def create_from_prompt(self, request, *args, **kwargs):
        serializer = serializers.FilePromptSerializer(data=request.data)
        serializer.is_valid(raise_exception=True)
        file_instance = serializer.save(mimetype="text/plain")
        job_instance = models.Job.objects.create(
            file=file_instance, type=models.JobType.FILE_TEXT
        )
        job_serializer = JobSerializer(job_instance)
        tasks.new_task(job_instance)
        return Response(job_serializer.data, status=status.HTTP_201_CREATED)

    @decorators.action(detail=True, methods=["GET"])
    def markdown(self, request, *args, file_id=None, **kwargs):
        obj: models.File = self.get_object()
        if not obj.markdown_file:
            return HttpResponseNotFound("No markdown file")
        modify_links = mistune.create_markdown(
            escape=False,
            renderer=MarkdownImageReplacer(
                self.request, models.FileImage.objects.filter(report__id=file_id)
            ),
        )
        return FileResponse(
            streaming_content=modify_links(obj.markdown_file.read().decode()),
            content_type="text/markdown",
            filename=f"{obj.name}-markdown.md",
        )

    @decorators.action(detail=True, pagination_class=Pagination("images"))
    def images(self, request, file_id=None, image=None):
        queryset = self.get_object().images.order_by("name")
        paginator = Pagination("images")

        page = paginator.paginate_queryset(queryset, request, self)

        if page is not None:
            serializer = ImageSerializer(page, many=True, context=dict(request=request))
            return paginator.get_paginated_response(serializer.data)

        serializer = self.get_serializer(queryset, many=True)
        return Response(serializer.data)

    def destroy(self, request, *args, file_id=None, **kwargs):
        reports.can_remove_report(reports.ReportView.path_param_as_report_id(file_id))
        return super().destroy(request, *args, **kwargs)

    def get_object(self) -> models.File:
        return super().get_object()

    @extend_schema(
        responses={
            (200, "application/pdf"): OpenApiTypes.BINARY,
            (404, "application/json"): DEFAULT_404_ERROR,
        },
        summary="Get the archived PDF copy of the File",
        description=textwrap.dedent(
            """
            When a file is uploaded, it is converted to pdf and saved.
            
            This endpoint is useful for loading the file in a generic pdf viewer (vs. trying to work with different filetypes of the original input).
            """
        ),
    )
    @decorators.action(detail=True, methods=["GET"], renderer_classes=[PDFRenderer])
    def pdf(self, request, *args, file_id=None, **kwargs):
        obj = self.get_object()
        if not obj.archived_pdf:
            return HttpResponseNotFound("No pdf file")
        _, _, name = obj.archived_pdf.name.rpartition("/")
        response = HttpResponse(obj.archived_pdf.open(), content_type="application/pdf")
        response["Content-Disposition"] = f'attachment; filename="{name}"'
        return response

    @extend_schema(
        responses={
            (200, "application/json"): dict,
            (404, "application/json"): DEFAULT_404_ERROR,
        },
        summary="Get data.json",
        description=textwrap.dedent(
            """
            Whan a file is uploaded, it is converted to pdf and saved.
            
            This endpoint is useful for loading the file in a generic pdf viewer (vs. trying to work with different filetypes of the original input).
            """
        ),
    )
    @decorators.action(detail=True, methods=["GET"], url_path="processing-log")
    def processing_log(self, request, *args, file_id=None, **kwargs):
        obj = self.get_object()
        return Response(obj.txt2detection_data)


@extend_schema_view(
    list=extend_schema(
        summary="Search and retrieve Jobs",
        description=textwrap.dedent(
            """
            Jobs track the status of File upload, conversion of the File into markdown and the extraction of the data from the text. For every new File added a job will be created. The `id` of a Job is printed in the POST responses, but you can use this endpoint to search for the `id` again, if required.
            """
        ),
        responses={200: JobSerializer, 400: DEFAULT_400_ERROR},
    ),
    retrieve=extend_schema(
        summary="Get a Job by STIX ID",
        description=textwrap.dedent(
            """
            Using a Job ID you can retrieve information about its state via this endpoint. This is useful to see if a Job is still processing, if an error has occurred (and at what stage), or if it has completed.
            """
        ),
    ),
)
class JobView(
    mixins.ListModelMixin, mixins.RetrieveModelMixin, viewsets.GenericViewSet
):
    openapi_tags = ["Jobs"]
    pagination_class = Pagination("jobs")
    serializer_class = serializers.JobSerializer
    lookup_url_kwarg = "job_id"

    class filterset_class(FilterSet):
        file_id = BaseInFilter(
            help_text="Filter the results by the ID of the File the Job was created from, e.g. `2632fd7a-ae33-4d35-9652-425e488c97af`."
        )
        state = Filter(help_text="Filter results by state")

    filter_backends = [DjangoFilterBackend, Ordering]
    ordering_fields = ["run_datetime", "state"]
    ordering = "run_datetime_descending"

    def get_queryset(self):
        return models.Job.objects.all()


class RulesFilterSet(FilterSet):
    indicator_id = BaseInFilter(
        help_text="Filter the results by the ID of the Rule. Pass the full STIX ID of the Indicator object, e.g. `indicator--3fa85f64-5717-4562-b3fc-2c963f66afa6`."
    )
    name = CharFilter(
        help_text="Filter by the name of the Rule (automatically created by the AI). Search is wildcard so `exploit` will match `exploited`, `exploits`, etc."
    )
    tlp_level = ChoiceFilter(
        help_text="Filter the Rules by the TLP level of the File they were generated from.",
        choices=models.TLP_Levels.choices,
    )
    created_by_ref = BaseInFilter(
        help_text="Filter the results by only the reports created by this identity. Pass the full STIX ID of the Identity object, e.g. `identity--b1ae1a15-6f4b-431e-b990-1b9678f35e15`."
    )
    sort = ChoiceFilter(
        help_text="Sort results by property",
        choices=[(f, f) for f in arangodb_helpers.RULES_SORT_FIELDS],
    )
    visible_to = CharFilter(
        help_text="Only show rules that are visible to the Identity id passed. e.g. passing `identity--b1ae1a15-6f4b-431e-b990-1b9678f35e15` would only show rules created by that identity (with any TLP level) or reports created by another identity ID but only if they are marked with `TLP:CLEAR` or `TLP:GREEN`."
    )
    # rule_type = ChoiceFilter(
    #     choices=[("base-rule", "Base Rule"), ("correlation-rule", "Correlation Rule")],
    #     help_text="Filter the results by the rule type, either `base-rule` or `correlation-rule`. If none passed will return all types."
    # )


@extend_schema_view()
class RuleView(viewsets.GenericViewSet):
    openapi_tags = ["Rules"]
    pagination_class = Pagination("rules")
    serializer_class = serializers.RuleSerializer
    lookup_url_kwarg = "indicator_id"

    lookup_value_regex = (
        r"indicator--[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}"
    )
    rule_type = None

    openapi_path_params = [
        OpenApiParameter(
            lookup_url_kwarg,
            location=OpenApiParameter.PATH,
            description="The `id` of the Indicator representing the Rule. e.g. `indicator--3fa85f64-5717-4562-b3fc-2c963f66afa6`. Note the UUID part of the STIX `id` used here will match the `id` in the Rule.",
        )
    ]

    def get_renderers(self):
        if self.action == "retrieve":
            return [renderers.JSONRenderer(), SigmaRuleRenderer()]
        return super().get_renderers()

    def list(self, request: request.Request, *args, **kwargs):
        request._request.GET = request.GET.copy()
        request._request.GET["rule_type"] = self.rule_type
        return arangodb_helpers.get_rules(request)

    @extend_schema(
        parameters=[
            OpenApiParameter(
                "format",
                description="The format of the Rule, either `sigma` (returns only the Sigma YAML) or `json` (returns the STIX 2.1 Indicator object containing the Rule). Make sure to set the `Accept` header correctly. You can also convert Base Rules into other detection languages using the convert endpoints.",
                enum=["sigma", "json"],
            )
        ]
    )
    def retrieve(self, request, *args, indicator_id=None, **kwargs):
        return arangodb_helpers.get_single_rule(
            indicator_id,
            version=request.query_params.get("version"),
            rule_type=self.rule_type,
        )

    @extend_schema(
        responses={
            200: {"type": "array", "items": {"type": "string", "format": "date-time"}}
        },
    )
    @decorators.action(methods=["GET"], detail=True, pagination_class=None)
    def versions(self, request, *args, indicator_id=None, **kwargs):
        return arangodb_helpers.get_single_rule_versions(
            indicator_id,
        )

    @extend_schema(
        request=serializers.RuleRevertSerializer,
        responses={200: serializers.JobSerializer, 400: DEFAULT_400_ERROR},
    )
    @decorators.action(methods=["PATCH"], detail=True, url_path="modify/revert")
    def revert(self, request, *args, indicator_id=None, **kwargs):
        s = serializers.RuleRevertSerializer(data=request.data)
        s.is_valid(raise_exception=True)
        versions = arangodb_helpers.get_single_rule_versions(indicator_id).data
        selected_version = s.initial_data["version"]
        if selected_version not in versions:
            raise validators.ValidationError("selected version does not exist")
        if selected_version == versions[0]:
            raise validators.ValidationError(
                "You cannot revert to the latest version of the rule"
            )
        report, indicator, all_objs = arangodb_helpers.get_objects_by_id(indicator_id)
        target_indicator = arangodb_helpers.get_single_rule(
            indicator_id, version=selected_version
        ).data
        new_rule, _ = arangodb_helpers.indicator_to_rule(target_indicator)
        if isinstance(self, BaseRuleView):
            job_instance = models.Job.objects.create(
                type=models.JobType.BASE_MODIFY,
                data=dict(
                    modification_method="revert",
                    indicator_id=indicator_id,
                    base_version=selected_version,
                ),
            )
            job_s = JobSerializer(job_instance)
            tasks.new_modify_rule_task(
                job_instance,
                indicator,
                new_rule.model_dump(mode="json", by_alias=True),
                report=report,
            )
            return Response(job_s.data, status=status.HTTP_201_CREATED)
        elif isinstance(self, CorrelationRuleView):
            job_instance = models.Job.objects.create(
                type=models.JobType.CORRELATION_MODIFY,
                data=dict(
                    modification_method="revert",
                    correlation_id=indicator_id,
                    base_version=selected_version,
                ),
            )
            job_s = CorrelationJobSerializer(job_instance)
            tasks.new_modify_rule_task(
                job_instance, indicator, new_rule.model_dump(mode="json", by_alias=True)
            )
            return Response(job_s.data, status=status.HTTP_201_CREATED)

    @extend_schema(
        request=serializers.RuleCloneSerializer,
        responses={201: JobSerializer, 400: DEFAULT_400_ERROR},
    )
    @decorators.action(methods=["POST"], detail=True)
    def clone(self, request, *args, indicator_id=None, **kwargs):
        original_indicator = self.retrieve(request, indicator_id=indicator_id)
        s = serializers.RuleCloneSerializer(data=request.data)
        s.is_valid(raise_exception=True)
        new_rule_indicator_id = "indicator--" + str(uuid.uuid4())
        job_instance = models.Job.objects.create(
            type=models.JobType.DUPLICATE_RULE,
            data=dict(
                cloned_from=indicator_id,
                indicator_id=new_rule_indicator_id,
                **s.validated_data,
            ),
        )
        job_s = JobSerializer(job_instance)
        tasks.new_clone_rule_task(job_instance)
        return Response(job_s.data, status=status.HTTP_201_CREATED)

    def destroy(self, request, *args, indicator_id=None, **kwargs):
        arangodb_helpers.delete_rule(
            indicator_id,
        )
        return Response(status=status.HTTP_204_NO_CONTENT)

    @decorators.action(methods=["GET"], detail=True)
    def objects(self, request, *args, indicator_id=None, **kwargs):
        return arangodb_helpers.get_objects_for_rule(
            indicator_id,
            request,
            version=request.query_params.get("version"),
            rule_type=self.rule_type,
        )

    @extend_schema(
        responses={
            (200, "application/json"): serializers.AttackNavigatorDomainSerializer,
            (404, "application/json"): DEFAULT_404_ERROR,
        },
        summary="Get the generated attack navigator",
        description=textwrap.dedent(
            """
            Whan a file is uploaded, it is converted to pdf and saved.
            
            This endpoint is useful for loading the file in a generic pdf viewer (vs. trying to work with different filetypes of the original input).
            """
        ),
    )
    @decorators.action(detail=True, methods=["GET"], url_path="attack-navigator")
    def nav_layer(self, request, *args, indicator_id=None, **kwargs):
        objects = arangodb_helpers.get_objects_for_rule(
            indicator_id,
            request,
            version=request.query_params.get("version"),
            rule_type=self.rule_type,
            with_limit=False,
        )
        objects.sort(key=lambda x: x["id"])
        techniques = {}
        report = None
        metadata = [dict(name="rule_id", value=indicator_id)]
        secondary_rules = set()

        for obj in objects:
            if (
                obj["type"] == "relationship"
                and obj["relationship_type"] == "related-to"
            ):
                ref = obj.get("external_references") and obj["external_references"][0]
                if (
                    ref
                    and ref["source_name"] == "mitre-attack"
                    and not ref["external_id"].startswith("TA")
                ):
                    comments = techniques.setdefault(ref["external_id"], [])
                    comments.append(obj["description"])

                    if obj['source_ref'] != indicator_id:
                        secondary_rules.add(obj['source_ref'])
            if obj["id"] == indicator_id:
                indicator = obj

            if obj["type"] == "report" and indicator_id in obj["object_refs"]:
                report = obj

        if report:
            metadata.append(dict(name="report_id", value=report["id"]))
        for s in secondary_rules:
            metadata.append(dict(name='secondary_rule', value=s))

        return Response(
            {
                "name": indicator["name"],
                "domain": "enterprise-attack",
                "versions": {
                    "layer": "4.5",
                    "navigator": "5.1.0",
                },
                "techniques": [
                    {
                        "comment": "|".join(comments),
                        "score": 100,
                        "showSubtechniques": True,
                        "techniqueID": techniqueId,
                    }
                    for techniqueId, comments in techniques.items()
                ],
                "gradient": {
                    "colors": ["#ffffff", "#ff6666"],
                    "minValue": 0,
                    "maxValue": 100,
                },
                "legendItems": [],
                "metadata": metadata,
                "links": [
                    {
                        "label": "Generated using siemrules",
                        "url": "https://github.com/muchdogesec/siemrules/",
                    }
                ],
                "layout": {"layout": "side"},
            }
        )


@extend_schema_view(
    list=extend_schema(
        summary="Search and retrieve Base Rules",
        description=textwrap.dedent(
            """
            Base Rules are created from the Files endpoints. During processing, txt2detection turns a File into one or more Base Rules. This endpoint will list all created Base Rules.
            """
        ),
        responses={200: serializers.RuleSerializer, 400: DEFAULT_400_ERROR},
    ),
    retrieve=extend_schema(
        summary="Get a Base Rule by STIX ID",
        description=textwrap.dedent(
            """
            Use this endpoint to retrieve a Base Rule using its STIX Indicator ID. The Indicator ID has the same UUID part as the Base Rule `id` property (e.g. `indicator--RULE_ID`)

            If you do not know the ID of the Base Rule you can use the GET Base Rules endpoint.
            """
        ),
        responses={
            200: serializers.RuleSerializer,
            (200, "application/sigma+yaml"): serializers.RuleSigmaSerializer,
        },
        parameters=[
            OpenApiParameter(
                "version",
                description="The version of the Base Rule you want to retrieve (e.g. `2025-04-04T06:12:59.482478Z`). The `version` value is the same as the STIX objects `modified` time. You can see all of the versions of a Base Rule using the version endpoint. ",
            )
        ],
    ),
    destroy=extend_schema(
        summary="Delete a Base Rule by STIX ID",
        description=textwrap.dedent(
            """
            Use this endpoint to delete a Base Rule using its STIX Indicator ID. All versions of the Rule that exist will be removed.

            This endpoint will remove the `indicator` representing the rule, and any relationships linking to the Indicator (e.g. linking the Indicator to an Observable object, MITRE ATT&CK object, etc.)

            IMPORTANT: this endpoint WILL NOT delete the STIX report object representing the file this rule was generated from, nor any STIX objects representing observables extracted from the rule, MITRE ATT&CK enrichments, or CVE enrichments.

            If you wish to delete the `report` object and all other Base Rules (`indicators`) connected to it, use the Delete Report endpoint.
            """
        ),
        responses={204: None, 400: DEFAULT_400_ERROR},
    ),
    revert=extend_schema(
        summary="Revert a Base Rule to an older version",
        description=textwrap.dedent(
            """
            This endpoint allows you to roll back (revert) the content of a Base Rule to an old version. This is particularly useful when newer versions of rules contain errors.

            This body requires the following values:

            * `version` The version of the Base Rule you want to retrieve (e.g. `2025-04-04T06:12:59.482478Z`). The `version` value is the same as the STIX objects `modified` time. You can see all of the versions of a Base Rule using the version endpoint.

            IMPORTANT: this request is not destructive (i.e will not delete the current version of the Base Rule). It will create a new version with the content of the rule at the point you want to revert to, except for `modified` times, which will match the time of the revert request.
            """
        ),
    ),
    clone=extend_schema(
        summary="Duplicate a Base Rule",
        description=textwrap.dedent(
            """
            This endpoint allows you to duplicate the content of a Base Rule into a new Base Rule. This is useful when you want to modify a Base Rule using a different author.

            It will also clone any external enrichments (MITRE ATT&CK and Vulnerabilities) as well as an extracted Observables.

            IMPORTANT: the duplicated Base Rule will be linked to the original Indicator object using an SRO created by the `identity` used to clone it. The Base Rule will also contain a reference to the original Base Rule. The cloned Base Rule will be directly linked to the original Report the original Base Rule was created from. It will File object.

            This body requires the following values:

            * `identity` (optional): This will be used as the `created_by_ref` for all created SDOs and SROs. This is a full STIX Identity JSON. e.g. `{"type":"identity","spec_version":"2.1","id":"identity--b1ae1a15-6f4b-431e-b990-1b9678f35e15","name":"Dummy Identity"}`. If no value is passed, the SIEM Rules identity object will be used.
            * `title` (optional): The `title` of the rule. If none passed, the current `title` of the rule will be used.
            * `description` (optional): The `description` of the rule. If none passed, the current `description` of the rule will be used.
            * `tlp_level` (optional, dictionary): either `clear`, `green`, `amber`, `amber+strict`, `red`. If none passed, the current TLP level of the rule will be used.

            You cannot modify any other values when duplicating a Base Rule. You can Edit the Base Rule after duplicating it.
            """
        ),
    ),
    versions=extend_schema(
        summary="Get all Versions of a Base Rule by STIX ID",
        description=textwrap.dedent(
            """
            Use this endpoint to retrieve all versions of a Base Rule using its STIX Indicator ID.

            Base Rules can be modified. Each modification creates a new version of a Base Rule.

            If you do not know the STIX Indicator ID of the Rule you can use the GET Rules endpoint. The Indicator ID has the same UUID part as the Base Rule `id` property (e.g. `indicator--RULE_ID`)

            You can use the list of versions returned on this endpoint to get a specific version of a rule using the GET Base Rule endpoint.
            """
        ),
    ),
    objects=extend_schema(
        summary="Get STIX Objects linked to Base Rule",
        description=textwrap.dedent(
            """
            A Base Rule can be directly linked to a range of other STIX objects representing MITRE ATT&CK references, CVE references, or detected observables (IoCs) inside the detection part of the rule.

            Use the endpoint to return all objects linked a Base Rule, including the Base Rule.
            """
        ),
        responses=arangodb_helpers.ArangoDBHelper.get_paginated_response_schema(),
        parameters=arangodb_helpers.ArangoDBHelper.get_schema_operation_parameters()
        + [
            OpenApiParameter(
                "version",
                description="The version of the rule you want to retrieve (e.g. `2025-04-04T06:12:59.482478Z`). The `version` value is the same as the STIX objects `modified` time. You can see all of the versions of a rule using the version endpoint.",
            ),
            OpenApiParameter(
                "types",
                many=True,
                explode=False,
                description="Filter the results by one or more STIX Object types",
                enum=OBJECT_TYPES,
            ),
            OpenApiParameter(
                "ignore_embedded_sro",
                type=bool,
                description="If set to `true` all embedded SROs are removed from the response.",
            ),
        ],
    ),
    modify_base_rule_from_prompt=extend_schema(
        summary="Modify a Base Rule using a natural language prompt",
        description=textwrap.dedent(
            """
            Use this endpoint to get AI to modify a Base Rule via a prompt.

            The following key / values are accepted in the body of the request:

            * `prompt` (required): The prompt you wish to send to the AI with instructions on how to modify or improve the rule. For example; Add MITRE ATT&CK Technique T1134 to this rule.
            * `ai_provider` (required): An AI provider and model to be used for rule generation in format `provider:model` e.g. `openai:gpt-4o`. This is a txt2detection setting.
            """
        ),
    ),
    modify_base_rule_manual=extend_schema(
        summary="Modify a Base Rule by modifying the YAML manually",
        description=textwrap.dedent(
            """
            Use this endpoint to modify a Base Rule using a Sigma YML input.

            You need to enter the entire YML of the rule, with the changes you'd like to make AND the values that should remain unchanged.

            If any properties are not passed, they will be removed from the rule. You must ensure all required properties are passed.

            For reference your updated rule MUST contain the following properties;

            * `title` (string): `title` of the rule. Will overwrite any existing value.
            * `logsource` (valid Sigma logsource): [a valid Sigma `logsource` entry](https://github.com/SigmaHQ/sigma-specification/blob/main/specification/sigma-rules-specification.md)
            * `detection` (valid Sigma detection): [a valid Sigma `detection` entry](https://github.com/SigmaHQ/sigma-specification/blob/main/specification/sigma-rules-specification.md)

            You should NOT pass the following properties when editing the rule (these are controlled by SIEM Rules). The request will pass BUT the values will remain the same;

            * `id`: is fixed across all versions of the rule
            * `date`: the `date` value is fixed across all versions of the rule, showing the date the rule was first created
            * `modified`: the `modified` time will be auto-updated based on the time of this modification
            * `author`: the `author` value will remain the same. If you wish to use a new `author` value, you must create a new rule. You can do this by cloning this rule using the Clone Rule endpoint.
            * `tags` (`tlp`): the `tlp.` tag value will remain the same. If you wish to use a new TLP value, you must create a new rule. You can do this by cloning this rule using the Clone Rule endpoint.

            [The rule will be validated against the Sigma specification](https://github.com/SigmaHQ/sigma-specification/blob/main/specification/sigma-rules-specification.md). You will receive an error if validation fails. If any part of the validation fails the rule will not be updated.
            """
        ),
    ),
)
class BaseRuleView(RuleView):
    rule_type = "base-rule"
    openapi_tags = ["Base Rules"]

    class filterset_class(RulesFilterSet):
        file_id = BaseInFilter(
            help_text="Filter the results by the ID of the File, e.g. `2632fd7a-ae33-4d35-9652-425e488c97af`."
        )
        attack_id = BaseInFilter(
            help_text="Filter the results return rules linked to a particular ATT&CK Technique. Pass the full ATT&CK ID, e.g. `T1047`. Note, only Base Rules have ATT&CK tags."
        )
        cve_id = BaseInFilter(
            help_text="Filter the results return rules linked to a particular CVE. Pass the full CVE ID, e.g. `CVE-2024-28374`. Note, only Base Rules have CVE tags."
        )
        report_id = BaseInFilter(
            help_text="Filter the results by the report_id of the rule. Pass the full STIX ID of the Indicator object, e.g. `report--3fa85f64-5717-4562-b3fc-2c963f66afa6`."
        )
        create_type = ChoiceFilter(
            choices=[(c, c) for c in ["file.file", "file.prompt", "file.sigma"]],
            help_text="Filter results by ingestion method",
        )

    @extend_schema(
        request=DRFDetection.drf_serializer,
        responses={200: serializers.RuleSerializer, 400: DEFAULT_400_ERROR},
    )
    @decorators.action(
        methods=["POST"],
        detail=True,
        parser_classes=[SigmaRuleParser],
        url_path="modify/yml",
    )
    def modify_base_rule_manual(self, request, *args, indicator_id=None, **kwargs):
        report, indicator, all_objs = arangodb_helpers.get_objects_by_id(indicator_id)

        if not report:
            raise ParseError(
                f"cannot find report associated with rule `{indicator_id}`"
            )

        old_detection = yaml_to_detection(
            indicator["pattern"], indicator.get("indicator_types", [])
        )
        merged_data = DRFDetection.merge_detection(old_detection, request.data)
        old_detection.indicator_types = indicator.get("indicator_types", [])
        s = DRFDetection.drf_serializer(data=merged_data)
        s.is_valid(raise_exception=True)
        DRFDetection.is_valid(s, request.data)
        detection = old_detection.model_copy(update=s.data)

        job_instance = models.Job.objects.create(
            type=models.JobType.BASE_MODIFY,
            data=dict(modification_method="sigma", indicator_id=indicator_id, **s.data),
        )
        job_s = JobSerializer(job_instance)
        tasks.new_modify_rule_task(
            job_instance,
            indicator,
            detection.model_dump(mode="json", by_alias=True),
            report=report,
        )
        return Response(job_s.data, status=status.HTTP_201_CREATED)

    @extend_schema(
        request=serializers.AIModifySerializer,
        responses={201: serializers.JobSerializer, 400: DEFAULT_400_ERROR},
    )
    @decorators.action(methods=["POST"], detail=True, url_path="modify/prompt")
    def modify_base_rule_from_prompt(self, request, *args, indicator_id=None, **kwargs):
        report, indicator, all_objs = arangodb_helpers.get_objects_by_id(indicator_id)
        s = serializers.AIModifySerializer(data=request.data)
        s.is_valid(raise_exception=True)

        job_instance = models.Job.objects.create(
            type=models.JobType.BASE_MODIFY,
            data=dict(
                modification_method="prompt", indicator_id=indicator_id, payload=s.data
            ),
        )
        job_s = JobSerializer(job_instance)
        tasks.new_modify_rule_task(job_instance, indicator, None, report=report)
        return Response(job_s.data, status=status.HTTP_201_CREATED)


@extend_schema_view(
    list=extend_schema(
        summary="Search and retrieve created Correlation Rules",
        description=textwrap.dedent(
            """
            Correlation Rules reference one or more Base Rules. You can retrieve them using those created in SIEM Rules using this endpoint.
            """
        ),
        responses={200: serializers.RuleSerializer, 400: DEFAULT_400_ERROR},
    ),
    retrieve=extend_schema(
        summary="Get a Correlation Rule by STIX ID",
        description=textwrap.dedent(
            """
            Use this endpoint to retrieve a Correlation Rule using its STIX Indicator ID. The Indicator ID has the same UUID part as the Base Rule id property (e.g. `indicator--RULE_ID`)

            If you do not know the ID of the Correlation Rule you can use the GET Correlation Rules endpoint.
            """
        ),
        responses={
            200: serializers.RuleSerializer,
            (200, "application/sigma+yaml"): serializers.RuleSigmaSerializer,
        },
        parameters=[
            OpenApiParameter(
                "version",
                description="The version of the Correlation Rule you want to retrieve (e.g. `2025-04-04T06:12:59.482478Z`). The `version` value is the same as the STIX objects `modified` time. You can see all of the versions of a rule using the version endpoint. ",
            )
        ],
    ),
    destroy=extend_schema(
        summary="Delete a Correlation Rule by STIX ID",
        description=textwrap.dedent(
            """
            Use this endpoint to delete a Correlation Rule. All versions of the Rule that exist will be removed.

            This endpoint will remove the `indicator` representing the Correlation Rule, and any relationships linking to the Indicator. This action will not modify any Base Rules inside the Correlation Rule (other than removing the connection between Base and Correlation Rule).
            """
        ),
        responses={204: None, 400: DEFAULT_400_ERROR},
    ),
    revert=extend_schema(
        summary="Revert a Correlation Rule to an older version",
        description=textwrap.dedent(
            """
            This endpoint allows you to roll back (revert) the content of a Correlation Rule to an old version.

            This body requires the following values:

            * `version` The version of the Correlation Rule you want to roll back (e.g. `2025-04-04T06:12:59.482478Z`). The `version` value is the same as the STIX objects `modified` time. You can see all of the versions of a rule using the version endpoint.

            Note, this will not delete the current version of the Correlation Rule. It will create a new version with the content of the rule at the point you want to revert to, except for `modified` times, which will match the time of revert.
            """
        ),
    ),
    clone=extend_schema(
        summary="Duplicate a Correlation Rule",
        description=textwrap.dedent(
            """
            This endpoint allows you to duplicate the content of a Correlation Rule into a new Correlation Rule. This is useful when you want to modify a Correlation Rule using a different author.

            IMPORTANT: the duplicated Correlation Rule will be linked to the original Indicator object using an SRO created by the `identity` used to clone it. The Correlation Rule will also contain a reference to the original Correlation Rule.

            This body requires the following values:

            * `identity` (optional): This will be used as the `created_by_ref` for all created SDOs and SROs. This is a full STIX Identity JSON. e.g. `{"type":"identity","spec_version":"2.1","id":"identity--b1ae1a15-6f4b-431e-b990-1b9678f35e15","name":"Dummy Identity"}`. If no value is passed, the SIEM Rules identity object will be used.
            * `title` (optional): The `title` of the rule. If none passed, the current `title` of the rule will be used.
            * `description` (optional): The `description` of the rule. If none passed, the current `description` of the rule will be used.
            * `tlp_level` (optional, dictionary): either `clear`, `green`, `amber`, `amber+strict`, `red`. If none passed, the current TLP level of the rule will be used.

            You cannot modify any other values when duplicating a Correlation Rule. You can Edit the Correlation Rule after duplicating it.

            If the request is successful, the response will contain a job `id` you can use with the Jobs endpoints.
            """
        ),
    ),
    versions=extend_schema(
        summary="Get all Versions of a Correlation Rule by STIX ID",
        description=textwrap.dedent(
            """
            Use this endpoint to retrieve all versions of a Correlation Rule using its STIX Indicator ID.

            Correlation Rules can be modified. Each modification creates a new version of a Correlation Rule.

            If you do not know the STIX Indicator ID of the Rule you can use the GET Rules endpoint. The Indicator ID has the same UUID part as the Correlation Rule `id` property (e.g. `indicator--RULE_ID`)

            You can use the list of versions returned on this endpoint to get a specific version of a rule using the GET Correlation Rule endpoint.
            """
        ),
    ),
    objects=extend_schema(
        summary="Get objects linked to Correlation Rule",
        description=textwrap.dedent(
            """
            A Correlation Rule is directly linked to the Indicator Objects representing the Base Rules it contains.

            Use the endpoint to return all objects linked a Correlation Rule, including the Correlation Rule itself.
            """
        ),
        responses=arangodb_helpers.ArangoDBHelper.get_paginated_response_schema(),
        parameters=arangodb_helpers.ArangoDBHelper.get_schema_operation_parameters()
        + [
            OpenApiParameter(
                "version",
                description="The version of the Correlation Rule you want to retrieve (e.g. `2025-04-04T06:12:59.482478Z`). The `version` value is the same as the STIX objects `modified` time. You can see all of the versions of a rule using the version endpoint.",
            ),
            OpenApiParameter(
                "ignore_embedded_sro",
                type=bool,
                description="If set to `true` all embedded SROs are removed from the response.",
            ),
            OpenApiParameter(
                "types",
                many=True,
                explode=False,
                description="Filter the results by one or more STIX Object types",
                enum=OBJECT_TYPES,
            ),
        ],
    ),
    modify_correlation_manual=extend_schema(
        summary="Manually edit a Correlation Rule by STIX ID",
        description=textwrap.dedent(
            """
            Use this endpoint to modify a Correlation Rule.

            You should only enter the parts of the Correlation Rule you wish to change. Any properties not passed will remain unchanged in the existing rule. To delete a value from a property (if optional), pass the property without the value.

            Enter the properties you want to change in YML format. You can change the following properties of a Correlation rule;

            * `title` (optional): if passed, cannot be blank. Used as the rule `title`. Will overwrite existing value.
            * `description` (optional): if passed, used as the rule `description`.  Will overwrite existing value.
            * `tags` (optional): in format `NAMESPACE.TAG` (e.g. `threat-actor.someone`). Cannot use the reserved namespaces `attack.`, `cve.` or `tlp`. If you wish to use reserved tags `attack.` or `cve,`, update one of the Base Rules used in this Correlation Rule with the desired tag. If you want to change the `tlp` level of the rule, you must delete and recreate or just clone it. If you want to delete all tags list, pass this property as empty (will not delete `tlp.` tags)
            * `status` (optional, dictionary): the status of the rule, either `stable`, `test`, `experimental`, `deprecated`, `unsupported`. Will overwrite any existing value.
            * `level` (optional, dictionary): the level of the rule, either `informational`, `low`, `medium`, `high`, `critical`. Will overwrite any existing value.
            * `falsepositives` (list of strings): the `falsepositives` displayed in the rule. Will append to any existing values. To delete all `falsepositives`, pass this property as empty.
            * `references` (list of urls): the `references` displayed in the rule. Must be URLs. Will append to any existing values. To delete all `references`, pass this property as empty.
            * `correlation` (optional): if passed, [should contain the full correlation part of the rule as defined by the Sigma specification](https://github.com/SigmaHQ/sigma-specification/blob/main/specification/sigma-correlation-rules-specification.md). The properties available are;
                * `rules` (required, rule ids): This property must contain one or more Sigma Base Rule ID's (e.g. `680c2e5b-3704-47e1-9a0c-4f6746211faf`). Do not include the `indicator--` part. Must be valid, else creation will fail.
                * `type` (required, dictionary): either `event_count`, `value_count`, `temporal`, `temporal_ordered`
                * `timespan` (required): defines a time period in which the correlation should be applied. The following format must be used: `number + letter (in lowercase)`. e.g. `90s` (90 seconds), `90m` (90 minutes), `90h` (90 hours), `90d` (90 days)
                * `condition` (required, dictionary): The condition defines when a correlation matches. Either `gt` (greater than), `gte` (greater than or equal to), `lt` (less than), `lte` (less than or equal to), `eq` (equal to).
                    * for an `event_count` correlation it defines the event count that must appear within the given time frame to match.
                    * for a `value_count` correlation it defines the count of distinct values contained in the field specified in the mandatory field attribute.
                    * for a `temporal` or `temporal_ordered` correlation it specified the count of different event types (Sigma rules matching) in the given time frame.
                * `aliases` (optional, list of aliases): defines field name aliases that are applied to correlated Sigma rules
                * `group-by` (optional, list of field names): optionally defines one or multiple fields which should be treated as separate event occurrence scope

            You cannot change the following properties (doing so will result in an error):

            * `id`: is fixed across all versions of the Correlation Rule
            * `related`: this is controlled by SIEM Rules
            * `date`: the `date` value will remain the same, showing the date the Correlation Rule was first created
            * `modified`: the `modified` time will be auto-updated based on the time of this modification
            * `author`: the `author` value will remain the same. If you wish to use a new `author` value, you must create a new Correlation Rule
            * `tlp_level`: modifying TLP is considered a major change to the Rule, thus you need to clone the Rule if you wish to change the TLP level

            The Correlation Rule will be validated against the Sigma specification. [You can read the specification here to see available properties and values allowed](https://github.com/SigmaHQ/sigma-specification/blob/main/specification/sigma-correlation-rules-specification.md).

            You will receive an error if validation fails. If any part of the validation fails the Correlation Rule will not be updated.

            If the request is successful, the response will contain a job `id` you can use with the Jobs endpoints.
            """
        ),
    ),
    modify_correlation_from_prompt=extend_schema(
        summary="Modify a Correlation Rule using a natural language prompt",
        description=textwrap.dedent(
            """
            Use this endpoint to get AI to modify a Rule via a Correlation prompt.

            The following key / values are accepted in the body of the request:

            * `prompt` (required): The prompt you wish to send to the AI with instructions on how to modify or improve the rule. For example; Add MITRE ATT&CK Technique T1134 to this rule.
            * `ai_provider` (required): An AI provider and model to be used for rule generation in format `provider:model` e.g. `openai:gpt-4o`. This is a txt2detection setting.

            If the request is successful, the response will contain a job `id` you can use with the Jobs endpoints.
            """
        ),
    ),
    create_from_sigma=extend_schema(
        summary="Create a Correlation Rule using YML",
        description=textwrap.dedent(
            """
            This endpoint is useful if you're comfortable writing a Correlation Rules manually.

            The body of the request accepts a valid Sigma YAML rule with the following properties;

            * `title` (required): used as the rule `title`
            * `description` (optional) used as the rule `description`
            * `author` (optional): A full STIX 2.1 identity object (make sure to properly escape). Will be validated by the STIX2 library. The ID is used to create the Indicator STIX object, and is used as the `author` property in the Sigma Correlation Rule. If not passed, the SIEM Rules Identity object will be used. e.g. `{"type":"identity","spec_version":"2.1","id":"identity--b1ae1a15-6f4b-431e-b990-1b9678f35e15","name":"Dummy Identity"}`
            * `date` (optional, date): will be used at the `created` time in the Indicator object generated and `date` value in the Sigma Correlation Rule. Default is now. Must be lower than `date`. In format `YYYY-MM-DD` (e.g. `2000-01-31`).
            * `modified` (optional, date): will be used at the `modified` time in the Indicator object generated and `modified` value in the Sigma Correlation Rule. Default is now. Must be higher than `date`. In format `YYYY-MM-DD` (e.g. `2000-01-31`).
            * `tags` (`tlp.` required): in format `NAMESPACE.TAG` (e.g. `threat-actor.someone`). Cannot use the reserved namespaces `attack.`, `cve.` If you wish to use reserved tags `attack.` or `cve,`, update one of the Base Rules used in this Correlation Rule with the desired tag.
                * `tlp.XXX`: you must assign a TLP level to the rule replacing XXX with either `clear`, `green`, `amber`, `amber+strict`, `red`. Not TLP cannot be changed once the rule is created. If none passed, default is `clear`
            * `references` (list of urls): the `references` displayed in the rule. Must be URLs. Will append to any existing values. To delete all `references`, pass this property as empty.
            * `status` (optional, dictionary): the status of the rule, either `stable`, `test`, `experimental`, `deprecated`, `unsupported`.
            * `level` (optional, dictionary): the level of the rule, either `informational`, `low`, `medium`, `high`, `critical`.
            * `falsepositives` (optional, list of strings): the `falsepositives` displayed in the rule.
            * `correlation` (required): [should contain the full correlation part of the rule as defined by the Sigma specification](https://github.com/SigmaHQ/sigma-specification/blob/main/specification/sigma-correlation-rules-specification.md). The properties available are;
                * `rules` (required, rule ids): This property must contain one or more Sigma Base Rule ID's (e.g. `680c2e5b-3704-47e1-9a0c-4f6746211faf`). Do not include the `indicator--` part. Must be valid, else creation will fail.
                * `type` (required, dictionary): either `event_count`, `value_count`, `temporal`, `temporal_ordered`
                * `timespan` (required): defines a time period in which the correlation should be applied. The following format must be used: `number + letter (in lowercase)`. e.g. `90s` (90 seconds), `90m` (90 minutes), `90h` (90 hours), `90d` (90 days)
                * `condition` (required, dictionary): The condition defines when a correlation matches. Either `gt` (greater than), `gte` (greater than or equal to), `lt` (less than), `lte` (less than or equal to), `eq` (equal to).
                    * for an `event_count` correlation it defines the event count that must appear within the given time frame to match.
                    * for a `value_count` correlation it defines the count of distinct values contained in the field specified in the mandatory field attribute.
                    * for a `temporal` or `temporal_ordered` correlation it specified the count of different event types (Sigma rules matching) in the given time frame.
                * `aliases` (optional, list of aliases): defines field name aliases that are applied to correlated Sigma rules
                * `group-by` (optional, list of field names): optionally defines one or multiple fields which should be treated as separate event occurrence scope

            You cannot pass the following properties (doing so will result in an error):

            * `id`: this is auto-generated by SIEM Rules
            * `related`: not supported
            
            If the request is successful, the response will contain a job `id` you can use with the Jobs endpoints.
            """
        ),
    ),
    create_from_prompt=extend_schema(
        summary="Create A Correlation Rule from a natural language prompt",
        description=textwrap.dedent(
            """
            Use this endpoint to create a Correlation Rule via an AI prompt.

            The body of the request accepts:

            * `rules` (required, rule ids): one or more Sigma Base Rule ID's (e.g. `680c2e5b-3704-47e1-9a0c-4f6746211faf`). Do not include the `indicator--` part. Must be valid, else creation will fail. The rules will be passed to the AI for consideration when generating the correlation.
            * `prompt` (required): The prompt you wish to send to the AI with instructions on how to create the correlation part of the rule. An example of;
                * creating Correlation from a single rule; `create a Sigma correlation when this Sigma rule with ID <ID> is triggered 5 times over a 10 minute period`
                * creating a Correlation from multiple rules; `create a Sigma correlation when the Sigma rule with ID <ID> is triggered followed by the Sigma rule with ID <ID> being triggered within a 2 minute period.
            * `ai_provider` (required): An AI provider and model to be used for rule generation in format `provider:model` e.g. `openai:gpt-4o`. This is a txt2detection setting.
            * `identity` (optional): A full STIX 2.1 identity object (make sure to properly escape). Will be validated by the STIX2 library. The ID is used to create the Indicator STIX object, and is used as the `author` property in the Sigma Correlation Rule. If not passed, the SIEM Rules Identity object will be used. e.g. `{"type":"identity","spec_version":"2.1","id":"identity--b1ae1a15-6f4b-431e-b990-1b9678f35e15","name":"Dummy Identity"}`
            * `date` (optional): will be used at the `created` time in the Indicator object generated and `date` value in the Sigma Correlation Rule. Default is now. Must be lower than `date`. In format `YYYY-MM-DD` (e.g. `2000-01-31`).
            * `modified`: will be used at the `modified` time in the Indicator object generated and `modified` value in the Sigma Correlation Rule. Default is now. Must be higher than `date`. In format `YYYY-MM-DD` (e.g. `2000-01-31`).
            * `tlp_level` (optional): TLP level assigned to the Indicator object and in the `tags` of the Sigma Correlation Rule. Either `clear`, `green`, `amber`, `amber+strict`, or `red`. Default if not passed is `clear`.

            You cannot pass the following properties (doing so will result in an error):

            * `id`: this is auto-generated by SIEM Rules
            * `title`: generated by the AI, can be modified later
            * `description`: generated by the AI, can be modified later
            * `related`: this is not considered during the creation of a new rule.
            * `tags`:  generated by the AI, can be modified later
                * Note, correlation rules never contain `attack.` or `cve.` namespaces in tags.
                * Note, TLP tag assigned using `tlp_level` parameter
            * `status`: always `experimental` in AI mode, can be modified later
            * `level`:  generated by the AI, can be modified later
            * `falsepositives`:  generated by the AI, can be modified later

            If the request is successful, the response will contain a job `id` you can use with the Jobs endpoints.
            """
        ),
    ),
)
class CorrelationRuleView(RuleView):
    openapi_tags = ["Correlation Rules"]
    rule_type = "correlation-rule"

    class filterset_class(RulesFilterSet):

        create_type = ChoiceFilter(
            choices=[(c, c) for c in ["correlation.prompt", "correlation.sigma"]],
            help_text="Filter results by ingestion method",
        )

    @extend_schema(
        request=correlations.serializers.DRFCorrelationRuleModify.drf_serializer,
        responses={201: serializers.JobSerializer, 400: DEFAULT_400_ERROR},
    )
    @decorators.action(
        methods=["POST"],
        detail=True,
        url_path="modify/yml",
        parser_classes=[SigmaRuleParser],
    )
    def modify_correlation_manual(self, request, *args, indicator_id=None, **kwargs):
        indicator = self.retrieve(request, indicator_id=indicator_id).data
        old_rule, _ = correlations.correlations.yaml_to_rule(indicator["pattern"])
        new_rule = (
            correlations.serializers.DRFCorrelationRuleModify.serialize_rule_from(
                old_rule, request.data
            )
        )
        job_instance = models.Job.objects.create(
            type=models.JobType.CORRELATION_MODIFY,
            data=dict(
                modification_method="sigma",
                correlation_id=indicator_id,
            ),
        )
        job_s = CorrelationJobSerializer(job_instance)
        tasks.new_modify_rule_task(
            job_instance, indicator, new_rule.model_dump(mode="json", by_alias=True)
        )
        return Response(job_s.data, status=status.HTTP_201_CREATED)

    @extend_schema(
        request=serializers.AIModifySerializer,
        responses={201: serializers.CorrelationJobSerializer, 400: DEFAULT_400_ERROR},
    )
    @decorators.action(methods=["POST"], detail=True, url_path="modify/prompt")
    def modify_correlation_from_prompt(
        self, request, *args, indicator_id=None, **kwargs
    ):
        _, indicator, _ = arangodb_helpers.get_objects_by_id(indicator_id)
        s = serializers.AIModifySerializer(data=request.data)
        s.is_valid(raise_exception=True)

        job_instance = models.Job.objects.create(
            type=models.JobType.CORRELATION_MODIFY,
            data=dict(
                modification_method="prompt", correlation_id=indicator_id, **s.data
            ),
        )
        job_s = CorrelationJobSerializer(job_instance)
        tasks.new_modify_rule_task(job_instance, indicator, None)
        return Response(job_s.data, status=status.HTTP_201_CREATED)

    def get_parsers(self):
        return super().get_parsers()

    @staticmethod
    def get_rules(rule_ids):
        r = request.Request(HttpRequest())
        rule_ids = [str(r) for r in rule_ids]
        indicator_ids = ["indicator--" + rule_id for rule_id in rule_ids]
        r.query_params.update(indicator_id=",".join(indicator_ids))
        indicators = arangodb_helpers.get_rules(r, paginate=False, nokeep=False)
        rules = {indicator["id"].replace("indicator--", "") for indicator in indicators}
        if non_existent_rules := set(rule_ids).difference(rules):
            raise validators.ValidationError(
                f"non existent rules in correlation {non_existent_rules}"
            )
        return indicators

    @extend_schema(
        request=DRFCorrelationRule.drf_serializer,
        responses={200: serializers.CorrelationJobSerializer, 400: DEFAULT_400_ERROR},
    )
    @decorators.action(
        methods=["POST"],
        detail=False,
        serializer_class=serializers.CorrelationJobSerializer,
        url_path="create/yml",
        parser_classes=[SigmaRuleParser],
    )
    def create_from_sigma(self, request, *args, **kwargs):
        rule_s = DRFCorrelationRule.drf_serializer(data=request.data)
        rule_s.is_valid(raise_exception=True)
        rule = DRFCorrelationRule.model_validate(rule_s.data)

        related_indicators = []
        if rule.correlation.rules:
            related_indicators = self.get_rules(rule.correlation.rules)

        job_instance = models.Job.objects.create(
            type=models.JobType.CORRELATION_SIGMA,
            data=dict(input_form="sigma", correlation_id=str(uuid.uuid4())),
        )
        job_s = CorrelationJobSerializer(job_instance)

        tasks.new_correlation_task(job_instance, rule, related_indicators, {})
        return Response(job_s.data)

    @extend_schema(
        request=CorrelationRuleSerializer,
        responses={200: serializers.CorrelationJobSerializer, 400: DEFAULT_400_ERROR},
    )
    @decorators.action(
        methods=["POST"],
        detail=False,
        serializer_class=CorrelationJobSerializer,
        url_path="create/prompt",
    )
    def create_from_prompt(self, request, *args, **kwargs):
        s = CorrelationRuleSerializer(data=request.data)
        s.is_valid(raise_exception=True)
        related_indicators = []
        if s.validated_data["rules"]:
            related_indicators = self.get_rules(s.validated_data["rules"])

        job_instance = models.Job.objects.create(
            type=models.JobType.CORRELATION_PROMPT,
            data=dict(
                input_form="ai_prompt", **s.data, correlation_id=str(uuid.uuid4())
            ),
        )
        job_s = CorrelationJobSerializer(job_instance)
        tasks.new_correlation_task(
            job_instance, s.validated_data, related_indicators, s.validated_data
        )
        return Response(job_s.data)


@extend_schema_view(
    list=extend_schema(
        summary="Search profiles",
        description=textwrap.dedent(
            """
            Profiles determine how txt2detection processes the file inputes.
            """
        ),
        responses={400: DEFAULT_400_ERROR, 200: ProfileSerializer},
    ),
    retrieve=extend_schema(
        summary="Get a profile",
        description=textwrap.dedent(
            """
            View the configuration of an existing profile. Note, existing profiles cannot be modified.
            """
        ),
        responses={
            400: DEFAULT_400_ERROR,
            404: DEFAULT_404_ERROR,
            200: ProfileSerializer,
        },
    ),
    create=extend_schema(
        summary="Create a new profile",
        description=textwrap.dedent(
            """
            Profiles define how file uploads are processed. You must have at least one profile defined, and it must be marked as default.
            """
        ),
        responses={400: DEFAULT_400_ERROR, 201: ProfileSerializer},
    ),
    destroy=extend_schema(
        summary="Delete a profile",
        description=textwrap.dedent(
            """
            Delete an existing profile.

            Note: it is not currently possible to delete a profile that is referenced in an existing object. You must delete the objects linked to the profile first.
            """
        ),
        responses={404: DEFAULT_404_ERROR, 204: None},
    ),
    extractors=extend_schema(
        summary="Show all observable types that can be extracted by all profiles",
        description==textwrap.dedent(
            """
            Show all observable types that can be extracted by all profiles",
            """
        ),
        responses={
            200: OpenApiResponse(
                list[str],
                examples=[
                    OpenApiExample(
                        "sample",
                        [
                            "ipv4-addr",
                            "ipv6-addr",
                            "email-addr",
                            "file.hashes.MD5",
                            "file.hashes.SHA-256",
                            "file.hashes.SSDEEP",
                            "mac-addr",
                            "x509-certificate",
                        ],
                        response_only=True,
                    )
                ],
            )
        },
    ),
)
class ProfileView(
    mixins.ListModelMixin,
    mixins.RetrieveModelMixin,
    mixins.DestroyModelMixin,
    mixins.CreateModelMixin,
    viewsets.GenericViewSet,
):
    openapi_tags = ["Profiles"]
    serializer_class = ProfileSerializer
    pagination_class = Pagination("profiles")
    lookup_url_kwarg = "profile_id"
    openapi_path_params = [
        OpenApiParameter(
            lookup_url_kwarg,
            location=OpenApiParameter.PATH,
            type=OpenApiTypes.UUID,
            description="The `id` of the Profile.",
        )
    ]

    ordering_fields = ["name", "created"]
    ordering = "created_descending"
    filter_backends = [DjangoFilterBackend, Ordering]

    class filterset_class(FilterSet):
        name = Filter(
            help_text="Searches Profiles by their `name`. Search is wildcard. For example, `ip` will return Profiles with names `ip-extractions`, `ips`, etc.",
            lookup_expr="icontains",
        )

    @extend_schema(request=None)
    @decorators.action(detail=True, methods=["PATCH"])
    def make_default(self, request, *args, profile_id=None, **kwargs):
        profile = self.get_object()
        profile.is_default = True
        profile.save()
        profile.refresh_from_db()
        return self.retrieve(request, profile_id=profile_id)

    def get_queryset(self):
        return models.Profile.objects

    @decorators.action(methods=["GET"], detail=False)
    def extractors(self, request, *args, **kwargs):
        from txt2detection.observables import STIX_PATTERNS_KEYS

        return Response(list(STIX_PATTERNS_KEYS))


@extend_schema_view(
    list=extend_schema(
        responses={204: {}},
        summary="Check if the service is running",
        description=textwrap.dedent(
            """
        If this endpoint returns a 204, the service is running as expected.
        """
        ),
    ),
    service=extend_schema(
        responses={200: serializers.HealthCheckSerializer},
        summary="Check the status of all external dependencies",
        description="Check the status of all external dependencies",
    ),
)
class HealthCheckView(viewsets.ViewSet):
    openapi_tags = ["Server Status"]

    def list(self, request, *args, **kwargs):
        return Response(status=status.HTTP_204_NO_CONTENT)

    @decorators.action(detail=False)
    def service(self, request, *args, **kwargs):
        return Response(status=200, data=self.check_status())

    @staticmethod
    def check_status():
        from txt2detection.credential_checker import check_statuses

        return check_statuses(test_llms=True)
