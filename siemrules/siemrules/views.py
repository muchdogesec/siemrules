from datetime import UTC, datetime
import io
import uuid
from rest_framework import (
    viewsets,
    parsers,
    decorators,
    mixins,
    renderers,
    exceptions,
    serializers as drf_serializers,
    status,
    validators,
)
from txt2detection.utils import parse_model
import yaml
from siemrules.siemrules import correlations, models, reports
from siemrules.siemrules import serializers
from siemrules.siemrules.correlations.serializers import CorrelationRuleSerializer, DRFCorrelationRule
from siemrules.siemrules.modifier import (
    DRFDetection,
    get_modification,
    modify_indicator,
    yaml_to_detection,
)
from siemrules.siemrules.serializers import (
    CorrelationJobSerializer,
    FileSerializer,
    ImageSerializer,
    JobSerializer,
)
from rest_framework.exceptions import NotFound, ParseError
from dogesec_commons.objects.helpers import OBJECT_TYPES

from rest_framework import request
from django.http import HttpRequest, HttpResponse
from drf_spectacular.utils import extend_schema, extend_schema_view, OpenApiParameter
import textwrap
import typing
from dogesec_commons.utils import Pagination, Ordering
from siemrules.siemrules.md_helper import MarkdownImageReplacer, mistune
from siemrules.siemrules.utils import SigmaRuleParser, SigmaRuleRenderer
from siemrules.worker import tasks
from rest_framework.response import Response
from django_filters.rest_framework import (
    FilterSet,
    DjangoFilterBackend,
    ChoiceFilter,
    CharFilter,
    BaseInFilter,
    Filter,
)

from siemrules.siemrules.autoschema import DEFAULT_400_ERROR, DEFAULT_404_ERROR

if typing.TYPE_CHECKING:
    from siemrules import settings
from django.http import FileResponse, HttpResponseNotFound
from siemrules.siemrules import arangodb_helpers

from drf_spectacular.views import SpectacularAPIView
from rest_framework.response import Response

class SchemaViewCached(SpectacularAPIView):
    _schema = None
    
    def _get_schema_response(self, request):
        version = self.api_version or request.version or self._get_version_parameter(request)
        if not self.__class__._schema:
            generator = self.generator_class(urlconf=self.urlconf, api_version=version, patterns=self.patterns)
            self.__class__._schema = generator.get_schema(request=request, public=self.serve_public)
        return Response(
            data=self.__class__._schema,
            headers={"Content-Disposition": f'inline; filename="{self._get_filename(request, version)}"'}
        )

@extend_schema_view(
    upload=extend_schema(
        summary="Upload an intelligence report to convert into Sigma Base Rules",
        description=textwrap.dedent(
            """
            Upload a file to be processed by SIEM Rules During processing a file is turned into markdown by [file2txt](https://github.com/muchdogesec/file2txt/), which is then passed to [txt2detection](https://github.com/muchdogesec/txt2detection/) to turn into rules.

            One or more Base Rules will be created from the report depending on its content.

            Files cannot be modified once uploaded. If you need to reprocess a file, you must upload it again.

            You cannot set the following properties when creating a rule in this mode:

            * `id`: generated by SIEM Rules
            * `title`: will be assigned by the AI
            * `description`: will be assigned by the AI
            * `status`: always `experimental`
            * `level`:  will be assigned by the AI

            The response will contain the Job information, including the Job `id`. This can be used with the GET Jobs by ID endpoint to monitor the status of the Job.
            """
        ),
    ),
    sigma=extend_schema(
        summary="Upload an existing Sigma Base Rule",
        description=textwrap.dedent(
            """
            If you have an existing Sigma Rule, you can upload it via this endpoint to create it as a Rule in SIEM Rules.

            [The file uploaded will be first validated against the Sigma rule specification](https://github.com/SigmaHQ/sigma-specification/blob/main/specification/sigma-rules-specification.md). If it passed this check, the file is then passed to [txt2detection](https://github.com/muchdogesec/txt2detection/) to turn it into STIX objects.

            Files cannot be modified once uploaded. If you need to reprocess a file, you must upload it again.

            Important, if the rule uploaded contains an existing `id` value, it will be changed by SIEM Rules to ensure collisions between IDs don't occur. The original `id` will be referenced inside the new rule under the `related` property.

            The response will contain the Job information, including the Job `id`. This can be used with the GET Jobs by ID endpoint to monitor the status of the Job.
            """
        ),
    ),
    text=extend_schema(
        summary="Enter a text prompt to convert into Sigma Base Rule",
        description=textwrap.dedent(
            """
            Create a file from a text prompt.

            One or more Base Rules will be created from the prompt depending on its content.

            During processing the created file is passed to [txt2detection](https://github.com/muchdogesec/txt2detection/) to turn into rules.

            Files cannot be modified once created from an input. If you need to reprocess a file, you must enter it again.

            The following key / values are accepted in the body of the request:

            * `text_input` (required): this is a string of text that will be passed to the AI to create the rule. Generally this should take the form of a prompt; e.g. `write a detection rule that identified failed logins`, `write a detection rule that detects 1.1.1.1 or 2.2.2.2`, etc.
            * `name` (required): This will be assigned to the File and Report object created. Note, the names of each detection rule generated will be automatically. Max 256 characters. This is a txt2detection setting.
            * `created` (optional) by default all object created times will take the time the script was run. If you want to explicitly set these times you can do so using this flag. Pass the value in the format `YYYY-MM-DDTHH:MM:SS` e.g. `2020-01-01T00:00:00`. This is a txt2detection setting.
            * `report_id` (optional): Pass a full STIX Report ID in the format `report--<UUID>` (e.g. `report--3fa85f64-5717-4562-b3fc-2c963f66afa6`. It will be use to generate the STIX Report ID generated to capture the file uploaded (the Indicator ID for the Rule will be different). If not passed, this value will be randomly generated for this file. Must be unique. This is a txt2detection setting.
            * `identity` (optional): This will be used as the `created_by_ref` for all created SDOs and SROs and as the `author` value in the Base Rule. This is a full STIX Identity JSON. e.g. `{"type":"identity","spec_version":"2.1","id":"identity--b1ae1a15-6f4b-431e-b990-1b9678f35e15","name":"Dummy Identity"}`. If no value is passed, the SIEM Rules identity object will be used. This is a txt2detection setting.
            * `labels` (optional): Will be added to the `labels` of the Report and Indicator SDOs created, and `tags` in the Rule itself. Must pass in format `namespace.value`. This is a txt2detection setting.
                * note: you cannot use the reserved `tlp`. Use the `tlp_level` setting to set this
                * note: you cannot use reserved namespaces `cve.` and `attack.`. The AI will add these based on the rule content.
            * `tlp_level` (optional): This will be assigned to all SDOs and SROs created and added to the Base Rule as a tag (e.g. `tlp.red`). SIEM Rules uses TLPv2. This is a txt2detection setting.
             * `license` (optional): [License of the rule according the SPDX ID specification](https://spdx.org/licenses/) (e.g. `MIT`). Will be added to the Rule. This is a txt2detection setting.
            * `defang` (optional): Whether to defang the observables in the text. e.g. turns `1.1.1[.]1` to `1.1.1.1` for extraction. This is a file2txt setting.
            * `ai_provider` (required): An AI provider and model to be used for rule generation in format `provider:model` e.g. `openai:gpt-4o`. This is a txt2detection setting.
            * `ignore_embedded_relationships` (optional, default: `false`): boolean, if `true` passed, this will stop ANY embedded relationships from being generated. This applies for all object types (SDO, SCO, SRO, SMO). If you want to target certain object types see `ignore_embedded_relationships_sro` and `ignore_embedded_relationships_sro` flags. This is a stix2arango setting.
            * `ignore_embedded_relationships_sro` (optional, default: false): boolean, if true passed, will stop any embedded relationships from being generated from SRO objects (type = `relationship`). This is a stix2arango setting.
            * `ignore_embedded_relationships_smo` (optional, default: false): boolean, if true passed, will stop any embedded relationships from being generated from SMO objects (type = `marking-definition`, `extension-definition`, `language-content`). This is a stix2arango setting.

            You cannot set the following properties when creating a rule in this mode:

            * `id`: generated by SIEM Rules
            * `title`: will be assigned by the AI
            * `description`: will be assigned by the AI
            * `status`: always `experimental`
            * `level`:  will be assigned by the AI
            * `references`: will be assigned by the AI

            The response will contain the Job information, including the Job `id`. This can be used with the GET Jobs by ID endpoint to monitor the status of the Job.
            """
        ),
    ),
    list=extend_schema(
        summary="Search and retrieve a list of uploaded Files",
        description=textwrap.dedent(
            """
            This endpoint allows you to search for Files you've uploaded. This endpoint is particularly useful if you want to download the original File uploaded or find the Report object created for the uploaded File so you can retrieve the objects created for it.
            """
        ),
        responses={200: FileSerializer, 400: DEFAULT_400_ERROR},
    ),
    destroy=extend_schema(
        summary="Delete a File by ID",
        description=textwrap.dedent(
            """
            This endpoint will delete a File using its ID. It will also delete the markdown, images and original file stored for this File.

            IMPORTANT: this request WILL delete the Report SDO created from the file, any any other STIX objects created from this file during extractions.
            """
        ),
    ),
    retrieve=extend_schema(
        summary="Get a File by ID",
        description=textwrap.dedent(
            """
            This endpoint will return information for a specific File using its ID.
            """
        ),
    ),
    images=extend_schema(
        responses={
            200: ImageSerializer(many=True),
            404: DEFAULT_404_ERROR,
            400: DEFAULT_400_ERROR,
        },
        filters=False,
        summary="Retrieve images found in a File",
        description=textwrap.dedent(
            """
            When [file2txt](https://github.com/muchdogesec/file2txt/) processes a file it will extract all images from the file and store them locally. You can see these images referenced in the markdown produced (see File markdown endpoint). This endpoint lists the image files found in the File selected.
            """
        ),
    ),
    markdown=extend_schema(
        responses={200: {}, 404: DEFAULT_404_ERROR},
        summary="Get the processed markdown for a File",
        description=textwrap.dedent(
            """
            When a file is uploaded it is converted to markdown using [file2txt](https://github.com/muchdogesec/file2txt/) which is subsequently used to make extractions from. This endpoint will return that output.
            
            This endpoint is useful for debugging issues in extractions when you think there could be an issue with the content being passed to the extractors.
            """
        ),
    ),
)
class FileView(
    mixins.ListModelMixin,
    mixins.DestroyModelMixin,
    mixins.RetrieveModelMixin,
    viewsets.GenericViewSet,
):
    openapi_tags = ["Files"]
    pagination_class = Pagination("files")
    serializer_class = serializers.FileSerializer
    parser_classes = [parsers.MultiPartParser]

    filter_backends = [DjangoFilterBackend, Ordering]
    ordering_fields = ["created", "name"]
    ordering = "created_descending"

    lookup_url_kwarg = "file_id"

    def get_queryset(self):
        return models.File.objects.all()

    class filterset_class(FilterSet):
        report_id = BaseInFilter(
            method="filter_report_id",
            help_text="Filter the results by the STIX Report ID generated for this File. Pass the full STIX ID, e.g. `report--3fa85f64-5717-4562-b3fc-2c963f66afa6`.",
        )
        name = CharFilter(
            help_text="Filter by the name of the File (entered on input). Search is wildcard so `exploit` will match `exploited`, `exploits`, etc."
        )
        tlp_level = ChoiceFilter(
            help_text="Filter the files by the TLP level selected at input.",
            choices=models.TLP_Levels.choices,
        )
        created_by_ref = BaseInFilter(
            "identity__id",
            help_text="Filter the results by only the Files created by this identity. Pass the full STIX ID of the Identity object, e.g. `identity--b1ae1a15-6f4b-431e-b990-1b9678f35e15`.",
        )

        def filter_report_id(self, qs, field_name, value: str):
            file_id = [reports.report_id_as_id(v) for v in value]
            return qs.filter(pk__in=file_id)

    @extend_schema(
        responses={200: serializers.JobSerializer, 400: DEFAULT_400_ERROR},
        request=serializers.FileSerializer,
    )
    @decorators.action(methods=["POST"], detail=False)
    def upload(self, request, *args, **kwargs):
        serializer = FileSerializer(data=request.data)
        serializer.is_valid(raise_exception=True)
        temp_file = request.FILES["file"]
        file_instance = serializer.save(mimetype=temp_file.content_type)
        job_instance = models.Job.objects.create(file=file_instance, type=models.JobType.FILE_FILE)
        job_serializer = JobSerializer(job_instance)
        tasks.new_task(job_instance)
        return Response(job_serializer.data)

    @extend_schema(
        responses={200: serializers.JobSerializer, 400: DEFAULT_400_ERROR},
        request=serializers.FileSigmaSerializer,
    )
    @decorators.action(methods=["POST"], detail=False)
    def sigma(self, request, *args, **kwargs):
        serializer = serializers.FileSigmaSerializer(data=request.data)
        serializer.is_valid(raise_exception=True)
        temp_file = request.FILES["sigma_file"]
        if temp_file.content_type != "application/x-yaml":
            validators.ValidationError("file content-type must be application/x-yaml")
        file_instance = serializer.save(mimetype=temp_file.content_type)
        job_instance = models.Job.objects.create(file=file_instance, type=models.JobType.FILE_SIGMA)
        job_serializer = JobSerializer(job_instance)
        tasks.new_task(job_instance)
        return Response(job_serializer.data)

    @extend_schema(
        responses={200: serializers.JobSerializer, 400: DEFAULT_400_ERROR},
        request=serializers.FilePromptSerializer,
    )
    @decorators.action(
        methods=["POST"], detail=False, parser_classes=[parsers.JSONParser]
    )
    def text(self, request, *args, **kwargs):
        serializer = serializers.FilePromptSerializer(data=request.data)
        serializer.is_valid(raise_exception=True)
        file_instance = serializer.save(mimetype="text/plain")
        job_instance = models.Job.objects.create(file=file_instance, type=models.JobType.FILE_TEXT)
        job_serializer = JobSerializer(job_instance)
        tasks.new_task(job_instance)
        return Response(job_serializer.data)

    @decorators.action(detail=True, methods=["GET"])
    def markdown(self, request, *args, file_id=None, **kwargs):
        obj: File = self.get_object()
        if not obj.markdown_file:
            return HttpResponseNotFound("No markdown file")
        modify_links = mistune.create_markdown(
            escape=False,
            renderer=MarkdownImageReplacer(
                self.request, models.FileImage.objects.filter(report__id=file_id)
            ),
        )
        return FileResponse(
            streaming_content=modify_links(obj.markdown_file.read().decode()),
            content_type="text/markdown",
            filename=f"{obj.name}-markdown.md",
        )

    @decorators.action(detail=True, pagination_class=Pagination("images"))
    def images(self, request, file_id=None, image=None):
        queryset = self.get_object().images.order_by("name")
        paginator = Pagination("images")

        page = paginator.paginate_queryset(queryset, request, self)

        if page is not None:
            serializer = ImageSerializer(page, many=True, context=dict(request=request))
            return paginator.get_paginated_response(serializer.data)

        serializer = self.get_serializer(queryset, many=True)
        return Response(serializer.data)
    
    def destroy(self, request, *args, file_id=None, **kwargs):
        reports.can_remove_report(reports.ReportView.path_param_as_report_id(file_id))
        return super().destroy(request, *args, **kwargs)


@extend_schema_view(
    list=extend_schema(
        summary="Search and retrieve Jobs",
        description=textwrap.dedent(
            """
            Jobs track the status of File upload, conversion of the File into markdown and the extraction of the data from the text. For every new File added a job will be created. The `id` of a Job is printed in the POST responses, but you can use this endpoint to search for the `id` again, if required.
            """
        ),
        responses={200: JobSerializer, 400: DEFAULT_400_ERROR},
    ),
    retrieve=extend_schema(
        summary="Get a Job by ID",
        description=textwrap.dedent(
            """
            Using a Job ID you can retrieve information about its state via this endpoint. This is useful to see if a Job is still processing, if an error has occurred (and at what stage), or if it has completed.
            """
        ),
    ),
)
class JobView(
    mixins.ListModelMixin, mixins.RetrieveModelMixin, viewsets.GenericViewSet
):
    openapi_tags = ["Jobs"]
    pagination_class = Pagination("jobs")
    serializer_class = serializers.JobSerializer
    lookup_url_kwarg = "job_id"

    class filterset_class(FilterSet):
        file_id = BaseInFilter(
            help_text="Filter the results by the ID of the File the Job was created from, e.g. `2632fd7a-ae33-4d35-9652-425e488c97af`."
        )
        state = Filter(help_text="Filter results by state")

    filter_backends = [DjangoFilterBackend, Ordering]
    ordering_fields = ["run_datetime", "state"]
    ordering = "run_datetime_descending"

    def get_queryset(self):
        return models.Job.objects.all()


@extend_schema_view(
    list=extend_schema(
        summary="Search and retrieve created Rules",
        description=textwrap.dedent(
            """
            Can be used to return Sigma Base and Correlation Rules.

            Base Rules are created from the Files endpoints. During processing, txt2detection turns a File into one or more Base Rules.

            Correlation Rules can be created using the Rule endpoints. Correlation Rules reference one or more Base Rules

            You can use this endpoint to retrieve either type of rule. Filter by `rule_type` if you want a specific type.
            """
        ),
        responses={200: serializers.RuleSerializer, 400: DEFAULT_400_ERROR},
    ),
    retrieve=extend_schema(
        summary="Get a Rule by ID",
        description=textwrap.dedent(
            """
            Can be used to return Sigma Base and Correlation Rules.

            Use this endpoint to retrieve a Rule using its STIX Indicator ID.

            If you do not know the ID of the Rule you can use the GET Rules endpoint.
            """
        ),
        responses={
            200: serializers.RuleSerializer,
            (200, "application/sigma+yaml"): serializers.RuleSigmaSerializer,
        },
        parameters=[
            OpenApiParameter(
                "version",
                description="The version of the rule you want to retrieve (e.g. `2025-04-04T06:12:59.482478Z`). The `version` value is the same as the STIX objects `modified` time. You can see all of the versions of a rule using the version endpoint. ",
            )
        ],
    ),
    destroy=extend_schema(
        summary="Delete a Rule by ID",
        description=textwrap.dedent(
            """
            Can be used to delete Sigma Base and Correlation Rules.

            Use this endpoint to delete a Rule. All versions of the Rule that exist will be removed.

            This endpoint will remove the `indicator` representing the rule, and any relationships linking to the Indicator.

            If you are deleting a Base Rule, this endpoint will not delete the STIX report object representing the file this rule was generated from, nor any STIX objects representing observables extracted from the rule, MITRE ATT&CK enrichments, or CVE enrichments.

            If you wish to delete the `report` object and all `indicators` (rules) connected to it, use the Delete Reports endpoint.
            """
        ),
    ),
    revert=extend_schema(
        summary="Revert a Rule to older version",
        description=textwrap.dedent(
            """
            Can be used to revert Sigma Base and Correlation Rules.

            This endpoint allows you to roll back (revert) the content of a Rule to an old version.

            This body requires the following values:

            * `version` The version of the rule you want to roll back (e.g. `2025-04-04T06:12:59.482478Z`). The `version` value is the same as the STIX objects `modified` time. You can see all of the versions of a rule using the version endpoint.

            Note, this will not delete the current version of the rule. It will create a new version with the content of the rule at the point you want to revert to, except for `modified` times, which will match the time of revert.
            """
        ),
    ),
    clone=extend_schema(
        summary="Duplicate a Rule",
        description=textwrap.dedent(
            """
            This endpoint allows you to duplicate the content of a Rule.

            It will also clone any external enrichments (MITRE ATT&CK and Vulnerabilities) as well as an extracted Observables.

            Note, this rule will be linked original Indicator object using an SRO created by the `identity` used to clone it. It will not be directly linked to a Report or File object.

            This body requires the following values:

            * `identity` (optional): This will be used as the `created_by_ref` for all created SDOs and SROs. This is a full STIX Identity JSON. e.g. `{"type":"identity","spec_version":"2.1","id":"identity--b1ae1a15-6f4b-431e-b990-1b9678f35e15","name":"Dummy Identity"}`. If no value is passed, the SIEM Rules identity object will be used.
            * `title` (optional): The `title` of the rule. If none passed, the current `title` of the rule will be used.
            * `description` (optional): The `description` of the rule. If none passed, the current `description` of the rule will be used.
            * `tlp_level` (optional, dictionary): either `clear`, `green`, `amber`, `amber+strict`, `red`. If none passed, the current TLP level of the rule will be used.

            You cannot modify any other values when cloning a rule. Edit the rule after cloning it to do this.
            """
        ),
    ),
    versions=extend_schema(
        summary="Get all Versions of a Rule by ID",
        description=textwrap.dedent(
            """
            Can be used to return Sigma Base and Correlation Rules.

            Rules can be modified over time. Each modification versions the Rule.

            Use this endpoint to retrieve all versions of a Rule using its STIX Indicator ID.

            If you do not know the ID of the Rule you can use the GET Rules endpoint.

            You can use the list of versions returned on this endpoint to get a specific version of a rule using the  GET Rule endpoint.
            """
        ),
    ),
    modify_base_rule_from_prompt=extend_schema(
        summary="Use AI to modify a Base Rule by ID",
        description=textwrap.dedent(
            """
            Use this endpoint to get AI to modify a Base Rule via a prompt.

            The following key / values are accepted in the body of the request:

            * `prompt` (required): The prompt you wish to send to the AI with instructions on how to modify or improve the rule. For example; Add MITRE ATT&CK Technique T1134 to this rule.
            * `ai_provider` (required): An AI provider and model to be used for rule generation in format `provider:model` e.g. `openai:gpt-4o`. This is a txt2detection setting.
            """
        ),
    ),
    modify_base_rule_manual=extend_schema(
        summary="Manually edit a Base Rule by ID",
        description=textwrap.dedent(
            """
            Use this endpoint to modify a Rule.

            You can enter the following properties. You should only enter the parts of the Rule you wish to change. Any properties/values not passed will remain unchanged in the rule.

            To delete a property entirely from a rule (if not required property), pass the property without a value (you cannot do this on required field)

            * `title` (string, cannot be blank if passed): `title` of the rule. Will overwrite any existing value.
            * `description` (string): the `description` of the rule. Will overwrite any existing value.
            * `status` (dictionary): the `status` of the rule, either `stable`, `test`, `experimental`, `deprecated`, `unsupported`. Will overwrite any existing value.
            * `level` (dictionary): the `level` of the rule, either `informational`, `low`, `medium`, `high`, `critical`
            * `tags` (string): case-insensitive (will all be converted to lower-case). Allowed `a-z`, `0-9`. Must use a namespaces (`NAMESPACE.TAG_VALUE`). e.g.`"namespace.label1" "namespace.label_2"` would create 2 labels. Added to both report and indicator objects created and the rule `tags`. Will append to any existing values EXCEPT for TLP. To delete all tags, first pass this property as empty, then perform your updates.
                * you can use reserved namespaces `cve.` and `attack.` when creating labels to perform external enrichment using Vulmatch and CTI Butler. All Indicators will be linked to these objects (AI enrichments link individual rules). Created tags will be appended to the list of AI generated tags.
                * note: you can use the namespace `tlp.`. A rule can only have one TLP level, so this will overwrite the existing TLP tag of the rule.
            * `license` (dictionary): [License of the rule according the SPDX ID specification](https://spdx.org/licenses/). Will overwrite any existing value.
            * `falsepositives` (list of strings): the `falsepositives` displayed in the rule. Will append to any existing values. To delete all `falsepositives`, first pass this property as empty, then perform your updates.
            * `references` (list of urls): the `references` displayed in the rule. Must be URLs. Will append to any existing values. To delete all `references`, first pass this property as empty, then perform your updates.
            * `logsource` (valid Sigma logsource): [a valid Sigma `logsource` entry](https://github.com/SigmaHQ/sigma-specification/blob/main/specification/sigma-rules-specification.md)
            * `detection` (valid Sigma detection): [a valid Sigma `detection` entry](https://github.com/SigmaHQ/sigma-specification/blob/main/specification/sigma-rules-specification.md)

            You cannot change the following properties:

            * `id`: is fixed across all versions of the rule
            * `date`: the `date` value will remain the same, showing the date the rule was first created
            * `modified`: the `modified` time will be auto-updated based on the time of this modification
            * `author`: the `author` value will remain the same. If you wish to use a new `author` value, you must create a new rule


            The rule will be validated against the Sigma specification. You will receive an error if validation fails. If any part of the validation fails the rule will not be updated.
            """
        ),
    ),
    objects=extend_schema(
        summary="Get objects linked to Base Rule",
        description=textwrap.dedent(
            """
            A Base Rule can be directly linked to a range of other STIX objects representing MITRE ATT&CK references, CVE references, or detected observables inside the detection part of the rule.

            Use the endpoint to return all objects linked a Base Rule, including the Base Rule.
            """
        ),
        responses=arangodb_helpers.ArangoDBHelper.get_paginated_response_schema(),
        parameters=arangodb_helpers.ArangoDBHelper.get_schema_operation_parameters() + [
            OpenApiParameter('version', description="The version of the rule you want to retrieve (e.g. `2025-04-04T06:12:59.482478Z`). The `version` value is the same as the STIX objects `modified` time. You can see all of the versions of a rule using the version endpoint.",),
            OpenApiParameter(
                "types",
                many=True,
                explode=False,
                description="Filter the results by one or more STIX Object types",
                enum=OBJECT_TYPES,
            ),
            OpenApiParameter('ignore_embedded_sro', type=bool, description="If set to `true` all embedded SROs are removed from the response."),
        ],
    ),
)
class RuleView(viewsets.GenericViewSet):
    openapi_tags = ["Rules"]
    pagination_class = Pagination("rules")
    serializer_class = serializers.RuleSerializer
    lookup_url_kwarg = "indicator_id"

    lookup_value_regex = r'indicator--[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}'
    rule_type = "base"

    openapi_path_params = [
        OpenApiParameter(
            lookup_url_kwarg,
            location=OpenApiParameter.PATH,
            description="The `id` of the Indicator. e.g. `indicator--3fa85f64-5717-4562-b3fc-2c963f66afa6`. Note the UUID part of the STIX `id` used here will match the `id` in the Rule.",
        )
    ]

    class filterset_class(FilterSet):
        file_id = BaseInFilter(
            help_text="Filter the results by the ID of the File, e.g. `2632fd7a-ae33-4d35-9652-425e488c97af`."
        )
        indicator_id = BaseInFilter(
            help_text="Filter the results by the ID of the Rule. Pass the full STIX ID of the Indicator object, e.g. `indicator--3fa85f64-5717-4562-b3fc-2c963f66afa6`."
        )
        name = CharFilter(
            help_text="Filter by the name of the Rule (automatically created by the AI). Search is wildcard so `exploit` will match `exploited`, `exploits`, etc."
        )
        tlp_level = ChoiceFilter(
            help_text="Filter the Rules by the TLP level of the File they were generated from.",
            choices=models.TLP_Levels.choices,
        )
        attack_id = BaseInFilter(
            help_text="Filter the results return rules linked to a particular ATT&CK Technique. Pass the full ATT&CK ID, e.g. `T1047`. Note, only Base Rules have ATT&CK tags."
        )
        cve_id = BaseInFilter(
            help_text="Filter the results return rules linked to a particular CVE. Pass the full CVE ID, e.g. `CVE-2024-28374`. Note, only Base Rules have CVE tags."
        )
        created_by_ref = BaseInFilter(
            help_text="Filter the results by only the reports created by this identity. Pass the full STIX ID of the Identity object, e.g. `identity--b1ae1a15-6f4b-431e-b990-1b9678f35e15`."
        )
        sort = ChoiceFilter(
            help_text="Sort results by property",
            choices=[(f, f) for f in arangodb_helpers.RULES_SORT_FIELDS],
        )
        visible_to = CharFilter(help_text="Only show rules that are visible to the Identity id passed. e.g. passing `identity--b1ae1a15-6f4b-431e-b990-1b9678f35e15` would only show rules created by that identity (with any TLP level) or reports created by another identity ID but only if they are marked with `TLP:CLEAR` or `TLP:GREEN`.")
        report_id = BaseInFilter(
            help_text="Filter the results by the report_id of the rule. Pass the full STIX ID of the Indicator object, e.g. `report--3fa85f64-5717-4562-b3fc-2c963f66afa6`."
        )
        rule_type = ChoiceFilter(
            choices=[("base-rule", "Base Rule"), ("correlation-rule", "Correlation Rule")],
            help_text="Filter the results by the rule type, either `base-rule` or `correlation-rule`. If none passed will return all types."
        )

    def get_renderers(self):
        if self.action == "retrieve":
            return [renderers.JSONRenderer(), SigmaRuleRenderer()]
        return super().get_renderers()

    def list(self, request, *args, **kwargs):
        return arangodb_helpers.get_rules(request)

    @extend_schema(
        parameters=[
            OpenApiParameter(
                "format",
                description="The format of the report, either `sigma` (returns only the Sigma YAML) or `json` (returns the STIX 2.1 Indicator object containing the Rule). Make sure to set the `Accept` header correctly.",
                enum=["sigma", "json"],
            )
        ]
    )
    def retrieve(self, request, *args, indicator_id=None, **kwargs):
        return arangodb_helpers.get_single_rule(
            indicator_id, version=request.query_params.get("version"),
        )

    @extend_schema(
        responses={
            200: {"type": "array", "items": {"type": "string", "format": "date-time"}}
        },
    )
    @decorators.action(methods=["GET"], detail=True, pagination_class=None)
    def versions(self, request, *args, indicator_id=None, **kwargs):
        return arangodb_helpers.get_single_rule_versions(
            indicator_id,
        )

    @extend_schema(
        request=DRFDetection.drf_serializer,
        responses={200: serializers.RuleSerializer, 400: DEFAULT_400_ERROR},
    )
    @decorators.action(methods=["POST"], detail=True, parser_classes=[SigmaRuleParser], url_path="modify/base-rule/manual")
    def modify_base_rule_manual(self, request, *args, indicator_id=None, **kwargs):
        report, indicator, all_objs = arangodb_helpers.get_objects_by_id(indicator_id)

        if not report:
            raise ParseError(f"cannot find report associated with rule `{indicator_id}`")
        
        old_detection = yaml_to_detection(
            indicator["pattern"], indicator.get("indicator_types", [])
        )
        data = DRFDetection.merge_detection(old_detection, request.data)
        s = DRFDetection.drf_serializer(data=data)
        s.is_valid(raise_exception=True)
        DRFDetection.is_valid(s, request.data)
        detection = DRFDetection.model_validate(s.data)

        return self.do_modify_base_rule(request, indicator_id, report, indicator, detection)

    def do_modify_base_rule(self, request, indicator_id, report, indicator, detection):
        new_objects = modify_indicator(report, indicator, detection)
        arangodb_helpers.modify_rule(
            indicator["id"],
            indicator["modified"],
            new_objects[0]["modified"],
            new_objects,
        )

        return self.retrieve(request, indicator_id=indicator_id)
    
    @extend_schema(
        request=serializers.AIModifySerializer,
        responses={200: serializers.RuleSerializer, 400: DEFAULT_400_ERROR},
    )
    @decorators.action(methods=['POST'], detail=True, url_path="modify/base-rule/ai")
    def modify_base_rule_from_prompt(self, request, *args, indicator_id=None, **kwargs):
        report, indicator, all_objs = arangodb_helpers.get_objects_by_id(indicator_id)
        s = serializers.AIModifySerializer(data=request.data)
        s.is_valid(raise_exception=True)
        old_detection = yaml_to_detection(
            indicator["pattern"], indicator.get("indicator_types", [])
        )
        input_text = report["description"]
        input_text = "<SKIPPED INPUT>"
        detection_container = get_modification(
            parse_model(s.data["ai_provider"]),
            input_text,
            old_detection,
            s.data["prompt"],
        )
        if not detection_container.success:
            raise exceptions.ParseError("txt2detection: failed to execute")

        return self.do_modify_base_rule(
            request, indicator_id, report, indicator, detection_container.detections[0]
        )
    
    @extend_schema(request=serializers.RuleRevertSerializer)
    @decorators.action(methods=['PATCH'], detail=True, url_path="modify/revert")
    def revert(self, request, *args, indicator_id=None, **kwargs):
        s = serializers.RuleRevertSerializer(data=request.data)
        s.is_valid(raise_exception=True)
        versions = arangodb_helpers.get_single_rule_versions(indicator_id).data
        selected_version = s.initial_data['version']
        if selected_version not in versions:
            raise validators.ValidationError("selected version does not exist")
        if selected_version == versions[0]:
            raise validators.ValidationError("You cannot revert to the latest version of the rule")
        rev = arangodb_helpers.delete_rule(indicator_id, rule_date=selected_version, delete=False)
        return self.retrieve(request, indicator_id=indicator_id)
    

    @extend_schema(request=serializers.RuleCloneSerializer)
    @decorators.action(methods=['POST'], detail=True)
    def clone(self, request, *args, indicator_id=None, **kwargs):
        s = serializers.RuleCloneSerializer(data=request.data)
        s.is_valid(raise_exception=True)
        new_rule_indicator_id = arangodb_helpers.make_clone(indicator_id, s.validated_data)
        return self.retrieve(request, indicator_id=new_rule_indicator_id)

    def destroy(self, request, *args, indicator_id=None, **kwargs):
        arangodb_helpers.delete_rule(indicator_id, 
        )
        return Response(status=status.HTTP_204_NO_CONTENT)

    @decorators.action(methods=["GET"], detail=True)
    def objects(self, request, *args, indicator_id=None, **kwargs):
        return arangodb_helpers.get_objects_for_rule(
            indicator_id, request, version=request.query_params.get("version"),
        )
    
@extend_schema_view(
    modify_correlation_manual=extend_schema(
        summary="Manually edit a Correlation Rule by ID",
        description=textwrap.dedent(
            """
            Use this endpoint to modify a Correlation Rule.

            You should only enter the parts of the Correlation Rule you wish to change. Any properties not passed will remain unchanged in the existing rule. To delete a value from a property (if optional), pass the property without the value.

            Enter the properties you want to change in YML format. You can change the following properties of a Correlation rule;

            * `title` (optional): if passed, cannot be blank. Used as the rule `title`. Will overwrite existing value.
            * `description` (optional): if passed, used as the rule `description`.  Will overwrite existing value.
            * `tags` (optional): in format `NAMESPACE.TAG` (e.g. `threat-actor.someone`). Cannot use the reserved namespaces `attack.`, `cve.` or `tlp`. If you wish to use reserved tags `attack.` or `cve,`, update one of the Base Rules used in this Correlation Rule with the desired tag. Will be appended to existing values. If you want to change the `tlp` level of the rule, you must delete and recreate or just clone it. If you want to delete all tags list, pass this property as empty (will not delete `tlp.` tags)
            * `status` (optional, dictionary): the status of the rule, either `stable`, `test`, `experimental`, `deprecated`, `unsupported`. Will overwrite any existing value.
            * `level` (optional, dictionary): the level of the rule, either `informational`, `low`, `medium`, `high`, `critical`. Will overwrite any existing value.
            * `falsepositives` (list of strings): the `falsepositives` displayed in the rule. Will append to any existing values. To delete all `falsepositives`, pass this property as empty.
            * `references` (list of urls): the `references` displayed in the rule. Must be URLs. Will append to any existing values. To delete all `references`, pass this property as empty.
            * `correlation` (optional): if passed, [should contain the full correlation part of the rule as defined by the Sigma specification](https://github.com/SigmaHQ/sigma-specification/blob/main/specification/sigma-correlation-rules-specification.md). The properties available are;
                * `rules` (required, rule ids): This property must contain one or more Sigma Base Rule ID's (e.g. `680c2e5b-3704-47e1-9a0c-4f6746211faf`). Do not include the `indicator--` part. Must be valid, else creation will fail.
                * `type` (required, dictionary): either `event_count`, `value_count`, `temporal`, `temporal_ordered`
                * `timespan` (required): defines a time period in which the correlation should be applied. The following format must be used: `number + letter (in lowercase)`. e.g. `90s` (90 seconds), `90m` (90 minutes), `90h` (90 hours), `90d` (90 days)
                * `condition` (required, dictionary): The condition defines when a correlation matches. Either `gt` (greater than), `gte` (greater than or equal to), `lt` (less than), `lte` (less than or equal to), `eq` (equal to).
                    * for an `event_count` correlation it defines the event count that must appear within the given time frame to match.
                    * for a `value_count` correlation it defines the count of distinct values contained in the field specified in the mandatory field attribute.
                    * for a `temporal` or `temporal_ordered` correlation it specified the count of different event types (Sigma rules matching) in the given time frame.
                * `aliases` (optional, list of aliases): defines field name aliases that are applied to correlated Sigma rules
                * `group-by` (optional, list of field names): optionally defines one or multiple fields which should be treated as separate event occurrence scope

            You cannot change the following properties (doing so will result in an error):

            * `id`: is fixed across all versions of the Correlation Rule
            * `related`: this is controlled by SIEM Rules
            * `date`: the `date` value will remain the same, showing the date the Correlation Rule was first created
            * `modified`: the `modified` time will be auto-updated based on the time of this modification
            * `author`: the `author` value will remain the same. If you wish to use a new `author` value, you must create a new Correlation Rule
            * `tlp_level`: modifying TLP is considered a major change to the Rule, thus you need to clone the Rule if you wish to change the TLP level

            The rule will be validated against the Sigma specification. [You can read the specification here to see available properties and values allowed](https://github.com/SigmaHQ/sigma-specification/blob/main/specification/sigma-correlation-rules-specification.md).

            You will receive an error if validation fails. If any part of the validation fails the rule will not be updated.
            
            """
        ),
    ),
    modify_correlation_from_prompt=extend_schema(
        summary="Use AI to modify a rule by ID",
        description=textwrap.dedent(
            """
            Use this endpoint to get AI to modify a Rule via a prompt.

            The following key / values are accepted in the body of the request:

            * `prompt` (required): The prompt you wish to send to the AI with instructions on how to modify or improve the rule. For example; Add MITRE ATT&CK Technique T1134 to this rule.
            * `ai_provider` (required): An AI provider and model to be used for rule generation in format `provider:model` e.g. `openai:gpt-4o`. This is a txt2detection setting.
            """
        ),
    ),

    create_from_sigma=extend_schema(
        summary="Create a Correlation Rule using YML",
        description=textwrap.dedent(
            """
            This endpoint is useful if you're comfortable writing a Sigma Correlation Rule manually.

            The body of the request accepts a valid Sigma YAML rule with the following properties;

            * `title` (required): used as the rule `title`
            * `description` (optional) used as the rule `description`
            * `author` (optional): A full STIX 2.1 identity object (make sure to properly escape). Will be validated by the STIX2 library. The ID is used to create the Indicator STIX object, and is used as the `author` property in the Sigma Correlation Rule. If not passed, the SIEM Rules Identity object will be used. e.g. `{"type":"identity","spec_version":"2.1","id":"identity--b1ae1a15-6f4b-431e-b990-1b9678f35e15","name":"Dummy Identity"}`
            * `date` (optional, date): will be used at the `created` time in the Indicator object generated and `date` value in the Sigma Correlation Rule. Default is now. Must be lower than `date`. In format `YYYY-MM-DD` (e.g. `2000-01-31`).
            * `modified` (optional, date): will be used at the `modified` time in the Indicator object generated and `modified` value in the Sigma Correlation Rule. Default is now. Must be higher than `date`. In format `YYYY-MM-DD` (e.g. `2000-01-31`).
            * `tags` (`tlp.` required): in format `NAMESPACE.TAG` (e.g. `threat-actor.someone`). Cannot use the reserved namespaces `attack.`, `cve.` If you wish to use reserved tags `attack.` or `cve,`, update one of the Base Rules used in this Correlation Rule with the desired tag.
                * `tlp.XXX`: you must assign a TLP level to the rule replacing XXX with either `clear`, `green`, `amber`, `amber+strict`, `red`. Not TLP cannot be changed once the rule is created.
            * `references` (list of urls): the `references` displayed in the rule. Must be URLs. Will append to any existing values. To delete all `references`, pass this property as empty.
            * `status` (optional, dictionary): the status of the rule, either `stable`, `test`, `experimental`, `deprecated`, `unsupported`.
            * `level` (optional, dictionary): the level of the rule, either `informational`, `low`, `medium`, `high`, `critical`.
            * `falsepositives` (optional, list of strings): the `falsepositives` displayed in the rule.
            * `correlation` (required): [should contain the full correlation part of the rule as defined by the Sigma specification](https://github.com/SigmaHQ/sigma-specification/blob/main/specification/sigma-correlation-rules-specification.md). The properties available are;
                * `rules` (required, rule ids): This property must contain one or more Sigma Base Rule ID's (e.g. `680c2e5b-3704-47e1-9a0c-4f6746211faf`). Do not include the `indicator--` part. Must be valid, else creation will fail.
                * `type` (required, dictionary): either `event_count`, `value_count`, `temporal`, `temporal_ordered`
                * `timespan` (required): defines a time period in which the correlation should be applied. The following format must be used: `number + letter (in lowercase)`. e.g. `90s` (90 seconds), `90m` (90 minutes), `90h` (90 hours), `90d` (90 days)
                * `condition` (required, dictionary): The condition defines when a correlation matches. Either `gt` (greater than), `gte` (greater than or equal to), `lt` (less than), `lte` (less than or equal to), `eq` (equal to).
                    * for an `event_count` correlation it defines the event count that must appear within the given time frame to match.
                    * for a `value_count` correlation it defines the count of distinct values contained in the field specified in the mandatory field attribute.
                    * for a `temporal` or `temporal_ordered` correlation it specified the count of different event types (Sigma rules matching) in the given time frame.
                * `aliases` (optional, list of aliases): defines field name aliases that are applied to correlated Sigma rules
                * `group-by` (optional, list of field names): optionally defines one or multiple fields which should be treated as separate event occurrence scope

            You cannot pass the following properties (doing so will result in an error):

            * `id`: this is auto-generated by SIEM Rules
            * `related`: not supported
            
            If the request is successful, the response will contain a job `id` you can use with the Jobs endpoints.
            """
        ),
    ),
    create_from_prompt=extend_schema(
        summary="Create A Correlation Rule from an AI prompt",
        description=textwrap.dedent(
            """
            Use this endpoint to create a Correlation Rule via an AI prompt.

            The body of the request accepts:

            * `rules` (required, rule ids): one or more Sigma Base Rule ID's (e.g. `680c2e5b-3704-47e1-9a0c-4f6746211faf`). Do not include the `indicator--` part. Must be valid, else creation will fail. The rules will be passed to the AI for consideration when generating the correlation.
            * `prompt` (required): The prompt you wish to send to the AI with instructions on how to create the correlation part of the rule. An example of;
                * creating Correlation from a single rule; `create a Sigma correlation when this Sigma rule with ID <ID> is triggered 5 times over a 10 minute period`
                * creating a Correlation from multiple rules; `create a Sigma correlation when the Sigma rule with ID <ID> is triggered followed by the Sigma rule with ID <ID> being triggered within a 2 minute period.
            * `ai_provider` (required): An AI provider and model to be used for rule generation in format `provider:model` e.g. `openai:gpt-4o`. This is a txt2detection setting.
            * `identity` (optional): A full STIX 2.1 identity object (make sure to properly escape). Will be validated by the STIX2 library. The ID is used to create the Indicator STIX object, and is used as the `author` property in the Sigma Correlation Rule. If not passed, the SIEM Rules Identity object will be used. e.g. `{"type":"identity","spec_version":"2.1","id":"identity--b1ae1a15-6f4b-431e-b990-1b9678f35e15","name":"Dummy Identity"}`
            * `date` (optional): will be used at the `created` time in the Indicator object generated and `date` value in the Sigma Correlation Rule. Default is now. Must be lower than `date`. In format `YYYY-MM-DD` (e.g. `2000-01-31`).
            * `modified`: will be used at the `modified` time in the Indicator object generated and `modified` value in the Sigma Correlation Rule. Default is now. Must be higher than `date`. In format `YYYY-MM-DD` (e.g. `2000-01-31`).
            * `tlp_level` (optional): TLP level assigned to the Indicator object and in the `tags` of the Sigma Correlation Rule. Either `clear`, `green`, `amber`, `amber+strict`, or `red`. Default if not passed is `clear`.

            You cannot pass the following properties (doing so will result in an error):

            * `id`: this is auto-generated by SIEM Rules
            * `title`: generated by the AI, can be modified later
            * `description`: generated by the AI, can be modified later
            * `related`: this is not considered during the creation of a new rule.
            * `tags`:  generated by the AI, can be modified later
                * Note, correlation rules never contain `attack.` or `cve.` namespaces in tags.
                * Note, TLP tag assigned using `tlp_level` parameter
            * `status`: always `experimental` in AI mode, can be modified later
            * `level`:  generated by the AI, can be modified later
            * `falsepositives`:  generated by the AI, can be modified later

            If the request is successful, the response will contain a job `id` you can use with the Jobs endpoints.
            """
        ),
    ),
    
)
class RuleViewWithCorrelationModifier(RuleView):
    @extend_schema(
        request=correlations.serializers.DRFCorrelationRuleModify.drf_serializer,
        responses={200: serializers.RuleSerializer, 400: DEFAULT_400_ERROR},
    )
    @decorators.action(methods=['POST'], detail=True, url_path="modify/correlation-rule/manual", parser_classes=[SigmaRuleParser])
    def modify_correlation_manual(self, request, *args, indicator_id=None, **kwargs):
        report, indicator, all_objs = arangodb_helpers.get_objects_by_id(indicator_id)
        old_rule, _ = correlations.correlations.yaml_to_rule(
            indicator["pattern"]
        )
        new_rule = correlations.serializers.DRFCorrelationRuleModify.serialize_rule_from(old_rule, request.data)

        return self.do_modify_correlation(request, indicator_id, report, indicator, new_rule)

    def do_modify_correlation(self, request, indicator_id, report, indicator, rule):
        for ref in indicator.get('external_references', []):
            if ref['source_name'] == "siemrules-type":
                rule_type = ref['external_id']
                break
        else:
            rule_type = "correlation.modify"
        _, _, rule.rule_id = indicator_id.rpartition('--')
        new_objects = correlations.correlations.add_rule_indicator(rule, [], rule_type, dict(modified=datetime.now(UTC)))
        arangodb_helpers.modify_rule(
            indicator["id"],
            indicator["modified"],
            new_objects[0]["modified"],
            new_objects,
        )

        return self.retrieve(request, indicator_id=indicator_id)
    
    @extend_schema(
        request=serializers.AIModifySerializer,
        responses={200: serializers.RuleSerializer, 400: DEFAULT_400_ERROR},
    )
    @decorators.action(methods=['POST'], detail=True, url_path="modify/correlation-rule/ai")
    def modify_correlation_from_prompt(self, request, *args, indicator_id=None, **kwargs):
        report, indicator, all_objs = arangodb_helpers.get_objects_by_id(indicator_id)
        s = serializers.AIModifySerializer(data=request.data)
        s.is_valid(raise_exception=True)
        old_detection, _ = correlations.correlations.yaml_to_rule(
            indicator["pattern"]
        )
        new_rule = correlations.correlations.get_modification(
            parse_model(s.data["ai_provider"]),
            "",
            old_detection,
            s.data["prompt"],
        )

        return self.do_modify_correlation(
            request, indicator_id, report, indicator, new_rule
        )


    def get_parsers(self):
        return super().get_parsers()

    def get_rules(self, rule_ids):
        r = request.Request(HttpRequest())
        rule_ids = [str(r) for r in rule_ids]
        indicator_ids = ["indicator--" + rule_id for rule_id in rule_ids]
        r.query_params.update(indicator_id=",".join(indicator_ids))
        indicators = arangodb_helpers.get_rules(r, paginate=False, nokeep=False)
        rules = {
            indicator["id"].replace("indicator--", "")
            for indicator in indicators
        }
        if non_existent_rules := set(rule_ids).difference(rules):
            raise validators.ValidationError(
                f"non existent rules in correlation {non_existent_rules}"
            )
        return indicators

    @extend_schema(
        request=DRFCorrelationRule.drf_serializer,
        responses={200: serializers.CorrelationJobSerializer, 400: DEFAULT_400_ERROR},
    )
    @decorators.action(methods=['POST'], detail=False, serializer_class=serializers.CorrelationJobSerializer, url_path="create/correlation-rule/manual", parser_classes=[SigmaRuleParser])
    def create_from_sigma(self, request, *args, **kwargs):
        rule_s = DRFCorrelationRule.drf_serializer(data=request.data)
        rule_s.is_valid(raise_exception=True)
        rule = DRFCorrelationRule.model_validate(rule_s.data)

        related_indicators = []
        if rule.correlation.rules:
            related_indicators = self.get_rules(rule.correlation.rules)

        job_instance = models.Job.objects.create(type=models.JobType.CORRELATION_SIGMA, data=dict(input_form='sigma', correlation_id=str(uuid.uuid4())))
        job_s = CorrelationJobSerializer(job_instance)

        tasks.new_correlation_task(job_instance, rule, related_indicators, {})
        return Response(job_s.data)
    

    @extend_schema(
        request=CorrelationRuleSerializer,
        responses={200: serializers.CorrelationJobSerializer, 400: DEFAULT_400_ERROR},
    )
    @decorators.action(methods=['POST'], detail=False, serializer_class=CorrelationJobSerializer, url_path="create/correlation-rule/ai")
    def create_from_prompt(self, request, *args, **kwargs):
        s = CorrelationRuleSerializer(data=request.data)
        s.is_valid(raise_exception=True)
        related_indicators = []
        if s.validated_data['rules']:
            related_indicators = self.get_rules(s.validated_data['rules'])

        job_instance = models.Job.objects.create(type=models.JobType.CORRELATION_PROMPT, data=dict(input_form='ai_prompt', **s.data, correlation_id=str(uuid.uuid4())))
        job_s = CorrelationJobSerializer(job_instance)
        tasks.new_correlation_task(job_instance, s.validated_data, related_indicators, s.validated_data)
        return Response(job_s.data)
